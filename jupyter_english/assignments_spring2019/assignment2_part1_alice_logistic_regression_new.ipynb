{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment2_part1_alice_logistic_regression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "31GmmAV2UWuu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://github.com/shravankoninti/mlcourse.ai-1/blob/master/img/ods_stickers.jpg?raw=1\" />\n",
        "    \n",
        "## [mlcourse.ai](https://mlcourse.ai) â€“ Open Machine Learning Course \n",
        "Authors: [Yury Kashnitskiy](https://yorko.github.io) (@yorko), Yury Isakov. Edited by Anna Tarelina (@feuerengel), and Kolchenko Sergey (@KolchenkoSergey). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose."
      ]
    },
    {
      "metadata": {
        "id": "aeTjl2IsUWux",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# <center> Assignment #2. Spring 2019\n",
        "## <center>  Competition 1. User Identification with Logistic Regression <br>(beating baselines in the \"Alice\" competition)\n",
        "\n",
        "    \n",
        "Today we are going to practice working with sparse matrices, training Logistic Regression models, and doing feature engineering. We will reproduce a couple of baselines in the  Kaggle Inclass competition [\"Catch Me If You Can: Intruder Detection through Webpage Session Tracking\"](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2) (a.k.a. \"Alice\"). More credits will be given for beating stronger baselines. \n",
        "\n",
        "Prior to working on the assignment, you'd better check out the corresponding course material:\n",
        " 1. [Classification, Decision Trees and k Nearest Neighbors](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic03_decision_trees_kNN/topic3_decision_trees_kNN.ipynb?flush_cache=true), the same as an interactive web-based [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-3-decision-trees-and-knn) (basics of machine learning are covered here)\n",
        " 2. Linear classification and regression in 5 parts: \n",
        "    - [ordinary least squares](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-1-ols)\n",
        "    - [linear classification](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-2-classification)\n",
        "    - [regularization](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-3-regularization)\n",
        "    - [logistic regression: pros and cons](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-4-more-of-logit)\n",
        "    - [validation](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-5-validation)\n",
        " 3. You can also practice with demo assignments, which are simpler and already shared with solutions: \n",
        "    - \" Sarcasm detection with logistic regression\": [assignment](https://www.kaggle.com/kashnitsky/a4-demo-sarcasm-detection-with-logit) + [solution](https://www.kaggle.com/kashnitsky/a4-demo-sarcasm-detection-with-logit-solution)\n",
        "    - \"Linear regression as optimization\": [assignment](https://www.kaggle.com/kashnitsky/a4-demo-linear-regression-as-optimization/edit) (solution cannot be officially shared)\n",
        "    - \"Exploring OLS, Lasso and Random Forest in a regression task\": [assignment](https://www.kaggle.com/kashnitsky/a6-demo-linear-models-and-rf-for-regression) + [solution](https://www.kaggle.com/kashnitsky/a6-demo-regression-solution)\n",
        " 4. Alice baseline with logistic regression and \"bag of sites\", [Kernel](https://www.kaggle.com/kashnitsky/alice-logistic-regression-baseline)\n",
        " 5. Correct time-aware cross-validation scheme, more features, and hyperparameter optimization, [Kernel](https://www.kaggle.com/kashnitsky/correct-time-aware-cross-validation-scheme)\n",
        " 6. Other [Kernels](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2/kernels?sortBy=voteCount&group=everyone&pageSize=20&competitionId=7173) in this competition. You can share yours as well, but not high-performing ones (Public LB MAE shall be < 0.95). Please don't spoil the competitive spirit. \n",
        " 7. If that's still not enough, watch two videos on logistic regression: [mlcourse.ai/video](https://mlcourse.ai/video)\n",
        "\n",
        "**Your task:**\n",
        " 1. \"Follow me\". Complete the missing code and submit your answers via [the google form](https://docs.google.com/forms/d/15PVw9CYlX6QnxRHKIDS161kGAq3v7iiO15W3qKTePEY). Use **the same email** as in A1 (for newcomers: remember your email and use it for all forms during the course). 12 credits max. for this part\n",
        " 2. \"Freeride\". Come up with good features to beat the baselines \"A2 baseline (10 credits)\" (**0.95640** Public LB ROC-AUC, press \"Load more\" in the bottom of the [Leaderboard](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2/leaderboard) to actually see it) and \"A2 strong baseline (20 credits)\" (**0.95965** Public LB ROC-AUC). As names suggest, you'll get 10 more credits for beating the first one, and 10 more (20 in total) for beating the second one. You need to name your [team](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2/team) (out of 1 person) in full accordance with the [course rating](https://docs.google.com/spreadsheets/d/1LAy1eK8vIONzIWgcCEaVmhKPSj579zK5lrECf_tQT60/edit?usp=sharing) (for newcomers: you need to name your team with your real full name). You can think of it as a part of the assignment.\n",
        " 3. If you've beaten \"A2 baseline (10 credits)\" or performed better, you need to upload your solution as described in [course roadmap](https://mlcourse.ai/roadmap) (\"Kaggle Inclass Competition Alice\" -> Rules). For all baselines that you see on Public Leaderboard, it's OK to beat them on Public LB as well. But 10 winners will be defined according to the private LB, which will be revealed by @yorko on March 11. \n",
        " \n",
        "### <center> Deadline for A2: 2019 March 10, 20:59 GMT (London time)"
      ]
    },
    {
      "metadata": {
        "id": "Ye9ctwFJUWu0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Part 1. Follow me"
      ]
    },
    {
      "metadata": {
        "id": "EDeYsHHHUWu4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src='https://github.com/shravankoninti/mlcourse.ai-1/blob/master/img/followme_alice.png?raw=1' width=50%>\n",
        "\n",
        "*image credit [@muradosmann](https://www.instagram.com/muradosmann/?hl=en)*"
      ]
    },
    {
      "metadata": {
        "id": "1kblukqNUWu5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import libraries and set desired options\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix, hstack\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I3RtRUCFUWu-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Problem description\n",
        "\n",
        "In this competition, we'll analyze the sequence of websites consequently visited by a particular person and try to predict whether this person is Alice or someone else. As a metric we will use [ROC AUC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)."
      ]
    },
    {
      "metadata": {
        "id": "tlGtJbwpUWu_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Data Downloading and Transformation\n",
        "Register on [Kaggle](www.kaggle.com), if you have not done it before.\n",
        "Go to the competition [page](https://inclass.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2) and download the data.\n",
        "\n",
        "First, read the training and test sets. Then we'll explore the data in hand and do a couple of simple exercises. "
      ]
    },
    {
      "metadata": {
        "id": "_GxyQunIWFaq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lBzeIBXZWI17",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train.csv\n",
        "\n",
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = '1fNEwqatg5VjL6q27S_yaRwVaZXUFL0u6' #https://drive.google.com/open?id=1fNEwqatg5VjL6q27S_yaRwVaZXUFL0u6\n",
        "downloaded = drive.CreateFile({'id': file_id})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PvtutZfRWNjn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "downloaded.GetContentFile('train_sessions.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5JiqHV-LWQUq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "file_id = '1mCdNKe_KZ77gZW24HAbwjXg4DTWK_l_Q' #https://drive.google.com/open?id=1mCdNKe_KZ77gZW24HAbwjXg4DTWK_l_Q\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1TIbX2SSWTxT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "downloaded.GetContentFile('test_sessions.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5L0QO5ZDWa7R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "downloaded.GetContentFile('site_dic.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QTpOaqDoWXID",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "file_id = '1VCXQVDkZsT9IWz-mvkP-GiUKxdJ3k101' #https://drive.google.com/open?id=1VCXQVDkZsT9IWz-mvkP-GiUKxdJ3k101\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kTuYK8mVXOIV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "downloaded.GetContentFile('site_dic.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "znne88LHXhGH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "28e3535d-c314-418e-9de8-0695faed682f"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 457,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json\tbaseline_3.csv\tsite_dic.pkl\t   train_sessions.csv\n",
            "baseline_1.csv\tbaseline_4.csv\tsubm1.csv\n",
            "baseline_2.csv\tsample_data\ttest_sessions.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T9qkzNg7WfRJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "cc3250f9-5a10-4d07-f493-0d4d02217b9d"
      },
      "cell_type": "code",
      "source": [
        "# read data from file\n",
        "# train = pd.read_csv(\"../input/train.csv\") \n",
        "# test = pd.read_csv(\"../input/test.csv\")\n",
        "\n",
        "train = pd.read_csv(\"train_sessions.csv\") \n",
        "test = pd.read_csv(\"test_sessions.csv\")\n",
        "\n",
        "# check the number of features and data points in train\n",
        "print(\"Number of data points in train: %d\" % train.shape[0])\n",
        "print(\"Number of features in train: %d\" % train.shape[1])\n",
        "\n",
        "# check the number of features and data points in test\n",
        "print(\"Number of data points in test: %d\" % test.shape[0])\n",
        "print(\"Number of features in test: %d\" % test.shape[1])"
      ],
      "execution_count": 458,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of data points in train: 253561\n",
            "Number of features in train: 22\n",
            "Number of data points in test: 82797\n",
            "Number of features in test: 21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "Pnwg3OFzUWvB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "dbd29908-c524-4ed3-9ae0-03b5e93c4652"
      },
      "cell_type": "code",
      "source": [
        "# Read the training and test data sets\n",
        "train_df = pd.read_csv('train_sessions.csv',\n",
        "                       index_col='session_id', parse_dates=['time1'])\n",
        "test_df = pd.read_csv('test_sessions.csv',\n",
        "                      index_col='session_id', parse_dates=['time1'])\n",
        "\n",
        "# Sort the data by time\n",
        "train_df = train_df.sort_values(by='time1')\n",
        "\n",
        "# Look at the first rows of the training set\n",
        "train_df.head()"
      ],
      "execution_count": 459,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site1</th>\n",
              "      <th>time1</th>\n",
              "      <th>site2</th>\n",
              "      <th>time2</th>\n",
              "      <th>site3</th>\n",
              "      <th>time3</th>\n",
              "      <th>site4</th>\n",
              "      <th>time4</th>\n",
              "      <th>site5</th>\n",
              "      <th>time5</th>\n",
              "      <th>...</th>\n",
              "      <th>time6</th>\n",
              "      <th>site7</th>\n",
              "      <th>time7</th>\n",
              "      <th>site8</th>\n",
              "      <th>time8</th>\n",
              "      <th>site9</th>\n",
              "      <th>time9</th>\n",
              "      <th>site10</th>\n",
              "      <th>time10</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>session_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21669</th>\n",
              "      <td>56</td>\n",
              "      <td>2013-01-12 08:05:57</td>\n",
              "      <td>55.0</td>\n",
              "      <td>2013-01-12 08:05:57</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54843</th>\n",
              "      <td>56</td>\n",
              "      <td>2013-01-12 08:37:23</td>\n",
              "      <td>55.0</td>\n",
              "      <td>2013-01-12 08:37:23</td>\n",
              "      <td>56.0</td>\n",
              "      <td>2013-01-12 09:07:07</td>\n",
              "      <td>55.0</td>\n",
              "      <td>2013-01-12 09:07:09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77292</th>\n",
              "      <td>946</td>\n",
              "      <td>2013-01-12 08:50:13</td>\n",
              "      <td>946.0</td>\n",
              "      <td>2013-01-12 08:50:14</td>\n",
              "      <td>951.0</td>\n",
              "      <td>2013-01-12 08:50:15</td>\n",
              "      <td>946.0</td>\n",
              "      <td>2013-01-12 08:50:15</td>\n",
              "      <td>946.0</td>\n",
              "      <td>2013-01-12 08:50:16</td>\n",
              "      <td>...</td>\n",
              "      <td>2013-01-12 08:50:16</td>\n",
              "      <td>948.0</td>\n",
              "      <td>2013-01-12 08:50:16</td>\n",
              "      <td>784.0</td>\n",
              "      <td>2013-01-12 08:50:16</td>\n",
              "      <td>949.0</td>\n",
              "      <td>2013-01-12 08:50:17</td>\n",
              "      <td>946.0</td>\n",
              "      <td>2013-01-12 08:50:17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114021</th>\n",
              "      <td>945</td>\n",
              "      <td>2013-01-12 08:50:17</td>\n",
              "      <td>948.0</td>\n",
              "      <td>2013-01-12 08:50:17</td>\n",
              "      <td>949.0</td>\n",
              "      <td>2013-01-12 08:50:18</td>\n",
              "      <td>948.0</td>\n",
              "      <td>2013-01-12 08:50:18</td>\n",
              "      <td>945.0</td>\n",
              "      <td>2013-01-12 08:50:18</td>\n",
              "      <td>...</td>\n",
              "      <td>2013-01-12 08:50:18</td>\n",
              "      <td>947.0</td>\n",
              "      <td>2013-01-12 08:50:19</td>\n",
              "      <td>945.0</td>\n",
              "      <td>2013-01-12 08:50:19</td>\n",
              "      <td>946.0</td>\n",
              "      <td>2013-01-12 08:50:19</td>\n",
              "      <td>946.0</td>\n",
              "      <td>2013-01-12 08:50:20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146670</th>\n",
              "      <td>947</td>\n",
              "      <td>2013-01-12 08:50:20</td>\n",
              "      <td>950.0</td>\n",
              "      <td>2013-01-12 08:50:20</td>\n",
              "      <td>948.0</td>\n",
              "      <td>2013-01-12 08:50:20</td>\n",
              "      <td>947.0</td>\n",
              "      <td>2013-01-12 08:50:21</td>\n",
              "      <td>950.0</td>\n",
              "      <td>2013-01-12 08:50:21</td>\n",
              "      <td>...</td>\n",
              "      <td>2013-01-12 08:50:21</td>\n",
              "      <td>946.0</td>\n",
              "      <td>2013-01-12 08:50:21</td>\n",
              "      <td>951.0</td>\n",
              "      <td>2013-01-12 08:50:22</td>\n",
              "      <td>946.0</td>\n",
              "      <td>2013-01-12 08:50:22</td>\n",
              "      <td>947.0</td>\n",
              "      <td>2013-01-12 08:50:22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            site1               time1  site2                time2  site3  \\\n",
              "session_id                                                                 \n",
              "21669          56 2013-01-12 08:05:57   55.0  2013-01-12 08:05:57    NaN   \n",
              "54843          56 2013-01-12 08:37:23   55.0  2013-01-12 08:37:23   56.0   \n",
              "77292         946 2013-01-12 08:50:13  946.0  2013-01-12 08:50:14  951.0   \n",
              "114021        945 2013-01-12 08:50:17  948.0  2013-01-12 08:50:17  949.0   \n",
              "146670        947 2013-01-12 08:50:20  950.0  2013-01-12 08:50:20  948.0   \n",
              "\n",
              "                          time3  site4                time4  site5  \\\n",
              "session_id                                                           \n",
              "21669                       NaN    NaN                  NaN    NaN   \n",
              "54843       2013-01-12 09:07:07   55.0  2013-01-12 09:07:09    NaN   \n",
              "77292       2013-01-12 08:50:15  946.0  2013-01-12 08:50:15  946.0   \n",
              "114021      2013-01-12 08:50:18  948.0  2013-01-12 08:50:18  945.0   \n",
              "146670      2013-01-12 08:50:20  947.0  2013-01-12 08:50:21  950.0   \n",
              "\n",
              "                          time5  ...                  time6  site7  \\\n",
              "session_id                       ...                                 \n",
              "21669                       NaN  ...                    NaN    NaN   \n",
              "54843                       NaN  ...                    NaN    NaN   \n",
              "77292       2013-01-12 08:50:16  ...    2013-01-12 08:50:16  948.0   \n",
              "114021      2013-01-12 08:50:18  ...    2013-01-12 08:50:18  947.0   \n",
              "146670      2013-01-12 08:50:21  ...    2013-01-12 08:50:21  946.0   \n",
              "\n",
              "                          time7  site8                time8  site9  \\\n",
              "session_id                                                           \n",
              "21669                       NaN    NaN                  NaN    NaN   \n",
              "54843                       NaN    NaN                  NaN    NaN   \n",
              "77292       2013-01-12 08:50:16  784.0  2013-01-12 08:50:16  949.0   \n",
              "114021      2013-01-12 08:50:19  945.0  2013-01-12 08:50:19  946.0   \n",
              "146670      2013-01-12 08:50:21  951.0  2013-01-12 08:50:22  946.0   \n",
              "\n",
              "                          time9 site10               time10 target  \n",
              "session_id                                                          \n",
              "21669                       NaN    NaN                  NaN      0  \n",
              "54843                       NaN    NaN                  NaN      0  \n",
              "77292       2013-01-12 08:50:17  946.0  2013-01-12 08:50:17      0  \n",
              "114021      2013-01-12 08:50:19  946.0  2013-01-12 08:50:20      0  \n",
              "146670      2013-01-12 08:50:22  947.0  2013-01-12 08:50:22      0  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 459
        }
      ]
    },
    {
      "metadata": {
        "id": "cOEN3Kp1bkNd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "39688e72-fbc2-4550-c210-7759c104775c"
      },
      "cell_type": "code",
      "source": [
        "# Read the training and test data sets, change paths if needed\n",
        "times = ['time%s' % i for i in range(1, 11)]\n",
        "train_df = pd.read_csv('train_sessions.csv',\n",
        "                       index_col='session_id', parse_dates=times)\n",
        "test_df = pd.read_csv('test_sessions.csv',\n",
        "                      index_col='session_id', parse_dates=times)\n",
        "\n",
        "# Sort the data by time\n",
        "train_df = train_df.sort_values(by='time1')\n",
        "\n",
        "# Look at the first rows of the training set\n",
        "train_df.head()"
      ],
      "execution_count": 460,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site1</th>\n",
              "      <th>time1</th>\n",
              "      <th>site2</th>\n",
              "      <th>time2</th>\n",
              "      <th>site3</th>\n",
              "      <th>time3</th>\n",
              "      <th>site4</th>\n",
              "      <th>time4</th>\n",
              "      <th>site5</th>\n",
              "      <th>time5</th>\n",
              "      <th>...</th>\n",
              "      <th>time6</th>\n",
              "      <th>site7</th>\n",
              "      <th>time7</th>\n",
              "      <th>site8</th>\n",
              "      <th>time8</th>\n",
              "      <th>site9</th>\n",
              "      <th>time9</th>\n",
              "      <th>site10</th>\n",
              "      <th>time10</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>session_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21669</th>\n",
              "      <td>56</td>\n",
              "      <td>2013-01-12 08:05:57</td>\n",
              "      <td>55.0</td>\n",
              "      <td>2013-01-12 08:05:57</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>...</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54843</th>\n",
              "      <td>56</td>\n",
              "      <td>2013-01-12 08:37:23</td>\n",
              "      <td>55.0</td>\n",
              "      <td>2013-01-12 08:37:23</td>\n",
              "      <td>56.0</td>\n",
              "      <td>2013-01-12 09:07:07</td>\n",
              "      <td>55.0</td>\n",
              "      <td>2013-01-12 09:07:09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>...</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77292</th>\n",
              "      <td>946</td>\n",
              "      <td>2013-01-12 08:50:13</td>\n",
              "      <td>946.0</td>\n",
              "      <td>2013-01-12 08:50:14</td>\n",
              "      <td>951.0</td>\n",
              "      <td>2013-01-12 08:50:15</td>\n",
              "      <td>946.0</td>\n",
              "      <td>2013-01-12 08:50:15</td>\n",
              "      <td>946.0</td>\n",
              "      <td>2013-01-12 08:50:16</td>\n",
              "      <td>...</td>\n",
              "      <td>2013-01-12 08:50:16</td>\n",
              "      <td>948.0</td>\n",
              "      <td>2013-01-12 08:50:16</td>\n",
              "      <td>784.0</td>\n",
              "      <td>2013-01-12 08:50:16</td>\n",
              "      <td>949.0</td>\n",
              "      <td>2013-01-12 08:50:17</td>\n",
              "      <td>946.0</td>\n",
              "      <td>2013-01-12 08:50:17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114021</th>\n",
              "      <td>945</td>\n",
              "      <td>2013-01-12 08:50:17</td>\n",
              "      <td>948.0</td>\n",
              "      <td>2013-01-12 08:50:17</td>\n",
              "      <td>949.0</td>\n",
              "      <td>2013-01-12 08:50:18</td>\n",
              "      <td>948.0</td>\n",
              "      <td>2013-01-12 08:50:18</td>\n",
              "      <td>945.0</td>\n",
              "      <td>2013-01-12 08:50:18</td>\n",
              "      <td>...</td>\n",
              "      <td>2013-01-12 08:50:18</td>\n",
              "      <td>947.0</td>\n",
              "      <td>2013-01-12 08:50:19</td>\n",
              "      <td>945.0</td>\n",
              "      <td>2013-01-12 08:50:19</td>\n",
              "      <td>946.0</td>\n",
              "      <td>2013-01-12 08:50:19</td>\n",
              "      <td>946.0</td>\n",
              "      <td>2013-01-12 08:50:20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146670</th>\n",
              "      <td>947</td>\n",
              "      <td>2013-01-12 08:50:20</td>\n",
              "      <td>950.0</td>\n",
              "      <td>2013-01-12 08:50:20</td>\n",
              "      <td>948.0</td>\n",
              "      <td>2013-01-12 08:50:20</td>\n",
              "      <td>947.0</td>\n",
              "      <td>2013-01-12 08:50:21</td>\n",
              "      <td>950.0</td>\n",
              "      <td>2013-01-12 08:50:21</td>\n",
              "      <td>...</td>\n",
              "      <td>2013-01-12 08:50:21</td>\n",
              "      <td>946.0</td>\n",
              "      <td>2013-01-12 08:50:21</td>\n",
              "      <td>951.0</td>\n",
              "      <td>2013-01-12 08:50:22</td>\n",
              "      <td>946.0</td>\n",
              "      <td>2013-01-12 08:50:22</td>\n",
              "      <td>947.0</td>\n",
              "      <td>2013-01-12 08:50:22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            site1               time1  site2               time2  site3  \\\n",
              "session_id                                                                \n",
              "21669          56 2013-01-12 08:05:57   55.0 2013-01-12 08:05:57    NaN   \n",
              "54843          56 2013-01-12 08:37:23   55.0 2013-01-12 08:37:23   56.0   \n",
              "77292         946 2013-01-12 08:50:13  946.0 2013-01-12 08:50:14  951.0   \n",
              "114021        945 2013-01-12 08:50:17  948.0 2013-01-12 08:50:17  949.0   \n",
              "146670        947 2013-01-12 08:50:20  950.0 2013-01-12 08:50:20  948.0   \n",
              "\n",
              "                         time3  site4               time4  site5  \\\n",
              "session_id                                                         \n",
              "21669                      NaT    NaN                 NaT    NaN   \n",
              "54843      2013-01-12 09:07:07   55.0 2013-01-12 09:07:09    NaN   \n",
              "77292      2013-01-12 08:50:15  946.0 2013-01-12 08:50:15  946.0   \n",
              "114021     2013-01-12 08:50:18  948.0 2013-01-12 08:50:18  945.0   \n",
              "146670     2013-01-12 08:50:20  947.0 2013-01-12 08:50:21  950.0   \n",
              "\n",
              "                         time5  ...                 time6  site7  \\\n",
              "session_id                      ...                                \n",
              "21669                      NaT  ...                   NaT    NaN   \n",
              "54843                      NaT  ...                   NaT    NaN   \n",
              "77292      2013-01-12 08:50:16  ...   2013-01-12 08:50:16  948.0   \n",
              "114021     2013-01-12 08:50:18  ...   2013-01-12 08:50:18  947.0   \n",
              "146670     2013-01-12 08:50:21  ...   2013-01-12 08:50:21  946.0   \n",
              "\n",
              "                         time7  site8               time8  site9  \\\n",
              "session_id                                                         \n",
              "21669                      NaT    NaN                 NaT    NaN   \n",
              "54843                      NaT    NaN                 NaT    NaN   \n",
              "77292      2013-01-12 08:50:16  784.0 2013-01-12 08:50:16  949.0   \n",
              "114021     2013-01-12 08:50:19  945.0 2013-01-12 08:50:19  946.0   \n",
              "146670     2013-01-12 08:50:21  951.0 2013-01-12 08:50:22  946.0   \n",
              "\n",
              "                         time9 site10              time10 target  \n",
              "session_id                                                        \n",
              "21669                      NaT    NaN                 NaT      0  \n",
              "54843                      NaT    NaN                 NaT      0  \n",
              "77292      2013-01-12 08:50:17  946.0 2013-01-12 08:50:17      0  \n",
              "114021     2013-01-12 08:50:19  946.0 2013-01-12 08:50:20      0  \n",
              "146670     2013-01-12 08:50:22  947.0 2013-01-12 08:50:22      0  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 460
        }
      ]
    },
    {
      "metadata": {
        "id": "KPXquMYuUWvJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The training data set contains the following features:\n",
        "\n",
        "- **site1** â€“ id of the first visited website in the session\n",
        "- **time1** â€“ visiting time for the first website in the session\n",
        "- ...\n",
        "- **site10** â€“ id of the tenth visited website in the session\n",
        "- **time10** â€“ visiting time for the tenth website in the session\n",
        "- **target** â€“ target variable, 1 for Alice's sessions, and 0 for the other users' sessions\n",
        "    \n",
        "User sessions are chosen in the way that they are shorter than 30 min. long and contain no more than 10 websites. I.e. a session is considered over either if a user has visited 10 websites or if a session has lasted over 30 minutes.\n",
        "\n",
        "There are some empty values in the table, it means that some sessions contain less than ten websites. Replace empty values with 0 and change columns types to integer. Also load the websites dictionary and check how it looks like:"
      ]
    },
    {
      "metadata": {
        "id": "HDjFy3PlUWvL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "cf26dda0-f63e-40ac-b297-3676348ace9e"
      },
      "cell_type": "code",
      "source": [
        "# Change site1, ..., site10 columns type to integer and fill NA-values with zeros\n",
        "sites = ['site%s' % i for i in range(1, 11)]\n",
        "train_df[sites] = train_df[sites].fillna(0).astype('int')\n",
        "test_df[sites] = test_df[sites].fillna(0).astype('int')\n",
        "\n",
        "# Load websites dictionary\n",
        "with open(r\"site_dic.pkl\", \"rb\") as input_file:\n",
        "    site_dict = pickle.load(input_file)\n",
        "\n",
        "# Create dataframe for the dictionary\n",
        "sites_dict = pd.DataFrame(list(site_dict.keys()), index=list(site_dict.values()), columns=['site'])\n",
        "print(u'Websites total:', sites_dict.shape[0])\n",
        "sites_dict.head()"
      ],
      "execution_count": 461,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Websites total: 48371\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25075</th>\n",
              "      <td>www.abmecatronique.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13997</th>\n",
              "      <td>groups.live.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42436</th>\n",
              "      <td>majeureliguefootball.wordpress.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30911</th>\n",
              "      <td>cdt46.media.tourinsoft.eu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8104</th>\n",
              "      <td>www.hdwallpapers.eu</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     site\n",
              "25075              www.abmecatronique.com\n",
              "13997                     groups.live.com\n",
              "42436  majeureliguefootball.wordpress.com\n",
              "30911           cdt46.media.tourinsoft.eu\n",
              "8104                  www.hdwallpapers.eu"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 461
        }
      ]
    },
    {
      "metadata": {
        "id": "kF1PXO9iUWvS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Brief Exploratory Data Analysis"
      ]
    },
    {
      "metadata": {
        "id": "dhSdTQiHUWvV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Before we start training models, we have to perform Exploratory Data Analysis ([EDA](https://en.wikipedia.org/wiki/Exploratory_data_analysis)). Today, we are going to perform a shorter version, but we will use other techniques as we move forward. Let's check which websites in the training data set are the most visited. As you can see, they are Google services and a bioinformatics website (a website with 'zero'-index is our missed values, just ignore it):"
      ]
    },
    {
      "metadata": {
        "id": "1WqLQjU_UWvX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "608a2105-9d84-452d-f35e-fc60311b649f"
      },
      "cell_type": "code",
      "source": [
        "# Top websites in the training data set\n",
        "top_sites = pd.Series(train_df[sites].values.flatten()\n",
        "                     ).value_counts().sort_values(ascending=False).head(5)\n",
        "print(top_sites)\n",
        "sites_dict.loc[top_sites.drop(0).index]"
      ],
      "execution_count": 462,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21     123776\n",
            "0      122730\n",
            "23      87619\n",
            "782     77055\n",
            "22      58258\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>www.google.fr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>www.google.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>782</th>\n",
              "      <td>annotathon.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>apis.google.com</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                site\n",
              "21     www.google.fr\n",
              "23    www.google.com\n",
              "782   annotathon.org\n",
              "22   apis.google.com"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 462
        }
      ]
    },
    {
      "metadata": {
        "id": "8u2Xmsy3UWvd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### 1. What kind of websites does Alice visit the most?\n",
        "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai, pinned thread __#a2_q1__*\n",
        "\n",
        "- videohostings\n",
        "- social networks\n",
        "- torrent trackers\n",
        "- news"
      ]
    },
    {
      "metadata": {
        "id": "hL11amTwUWve",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "0e6e4c9f-d7a5-4755-e695-4a653433364c"
      },
      "cell_type": "code",
      "source": [
        "# You code here\n",
        "# Top websites in the training data set\n",
        "top_sites = pd.Series(train_df[train_df['target'] == 1][sites].values.flatten()).value_counts().sort_values(ascending=False).head(5)\n",
        "print(top_sites)\n",
        "# sites_dict.loc[top_sites.drop(0).index]\n",
        "\n",
        "site_dict_2 = {y:x for x,y in site_dict.items()}\n",
        "site_dict_2.items()\n",
        "\n",
        "for siteid, website in site_dict_2.items():\n",
        "  if siteid == 77:\n",
        "    print('{0} corresponds to {1}'.format(siteid, website))\n",
        "  if siteid == 80:\n",
        "    print('{0} corresponds to {1}'.format(siteid, website))"
      ],
      "execution_count": 463,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "77    1382\n",
            "80    1354\n",
            "76    1307\n",
            "29     897\n",
            "21     857\n",
            "dtype: int64\n",
            "80 corresponds to s.youtube.com\n",
            "77 corresponds to i1.ytimg.com\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a0MQqde5UWvi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let us look at the timestamps and try to characterize sessions as timeframes:"
      ]
    },
    {
      "metadata": {
        "id": "xGN2o4hTUWvk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "9279fbfc-c074-46c4-d5f3-6e7652970861"
      },
      "cell_type": "code",
      "source": [
        "# Create a separate dataframe where we will work with timestamps\n",
        "time_df = pd.DataFrame(index=train_df.index)\n",
        "time_df['target'] = train_df['target']\n",
        "\n",
        "# Find sessions' starting and ending\n",
        "time_df['min'] = train_df[times].min(axis=1)\n",
        "time_df['max'] = train_df[times].max(axis=1)\n",
        "\n",
        "# Calculate sessions' duration in seconds\n",
        "time_df['seconds'] = (time_df['max'] - time_df['min']) / np.timedelta64(1, 's')\n",
        "\n",
        "print(time_df.head())\n",
        "\n",
        "\n",
        "# Find the test dataset time \n",
        "\n",
        "time_test_df = pd.DataFrame(index=test_df.index)\n",
        "# time_test_df['target'] = test_df['target']\n",
        "\n",
        "# Find sessions' starting and ending\n",
        "time_test_df['min'] = test_df[times].min(axis=1)\n",
        "time_test_df['max'] = test_df[times].max(axis=1)\n",
        "\n",
        "# Calculate sessions' duration in seconds\n",
        "time_test_df['seconds'] = (time_test_df['max'] - time_test_df['min']) / np.timedelta64(1, 's')\n",
        "\n",
        "print(time_test_df.head())"
      ],
      "execution_count": 464,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            target                 min                 max  seconds\n",
            "session_id                                                         \n",
            "21669            0 2013-01-12 08:05:57 2013-01-12 08:05:57      0.0\n",
            "54843            0 2013-01-12 08:37:23 2013-01-12 09:07:09   1786.0\n",
            "77292            0 2013-01-12 08:50:13 2013-01-12 08:50:17      4.0\n",
            "114021           0 2013-01-12 08:50:17 2013-01-12 08:50:20      3.0\n",
            "146670           0 2013-01-12 08:50:20 2013-01-12 08:50:22      2.0\n",
            "                           min                 max  seconds\n",
            "session_id                                                 \n",
            "1          2014-10-04 11:19:53 2014-10-04 11:20:00      7.0\n",
            "2          2014-07-03 11:00:28 2014-07-03 11:01:53     85.0\n",
            "3          2014-12-05 15:55:12 2014-12-05 15:56:36     84.0\n",
            "4          2014-11-04 10:03:19 2014-11-04 10:03:23      4.0\n",
            "5          2014-05-16 15:05:31 2014-05-16 15:05:44     13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rAVP6Cq2UWvq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In order to perform the next task, generate descriptive statistics as you did in the first assignment.\n",
        "\n",
        "*In the next question, we are using the notion of \"approximately the same\". To be strict, let's define it: $a$ is approximately the same as $b$ ($a \\approx b $) if their difference is less than or equal to 5% of the maximum between $a$ and $b$, i.e. $a \\approx b \\leftrightarrow \\frac{|a-b|}{max(a,b)} \\leq 0.05$.*\n",
        "\n",
        "##### 2. Select all correct statements:\n",
        "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai, pinned thread __#a2_q2__*\n",
        "\n",
        "- on average, Alice's session is shorter than that of other users\n",
        "- more than 1% of all sessions in the dataset belong to Alice\n",
        "- minimum and maximum durations of Alice's and other users' sessions are approximately the same\n",
        "- standard deviation of Alice's sessions duration is approximately the same as for non-Alice's sessions\n",
        "- less than a quarter of Alice's sessions are greater than or equal to 40 seconds"
      ]
    },
    {
      "metadata": {
        "id": "awUXk3IzUWvr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "24aa4d4a-ec7e-4476-df7a-552af622b32b"
      },
      "cell_type": "code",
      "source": [
        "# You code here\n",
        "alice_time_df = time_df[time_df['target'] == 1]\n",
        "print(alice_time_df['seconds'].mean())\n",
        "\n",
        "non_alice_time_df = time_df[time_df['target'] == 0]\n",
        "print(non_alice_time_df['seconds'].mean())\n"
      ],
      "execution_count": 465,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "52.29647366129734\n",
            "139.28237232552215\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DeiPIj_Pg09I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "8306af1d-fc0c-4ee8-882e-9419b683ffaa"
      },
      "cell_type": "code",
      "source": [
        "print(time_df['target'].value_counts())\n",
        "print(2297/251264)"
      ],
      "execution_count": 466,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    251264\n",
            "1      2297\n",
            "Name: target, dtype: int64\n",
            "0.009141779164544065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M65X98qVhSUo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "e231a8dc-c9bc-4e3f-e7bb-c7740f769b0d"
      },
      "cell_type": "code",
      "source": [
        "# time_df.groupby(['target'])('seconds').min()\n",
        "\n",
        "time_df.groupby(['target'])\\\n",
        "  .agg({'seconds': [np.mean, np.sum, np.min, np.max, np.std]})\n"
      ],
      "execution_count": 467,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"5\" halign=\"left\">seconds</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>sum</th>\n",
              "      <th>amin</th>\n",
              "      <th>amax</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>139.282372</td>\n",
              "      <td>34996646.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>296.653518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>52.296474</td>\n",
              "      <td>120125.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1763.0</td>\n",
              "      <td>153.309014</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           seconds                                     \n",
              "              mean         sum amin    amax         std\n",
              "target                                                 \n",
              "0       139.282372  34996646.0  0.0  1800.0  296.653518\n",
              "1        52.296474    120125.0  0.0  1763.0  153.309014"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 467
        }
      ]
    },
    {
      "metadata": {
        "id": "qqI8BTew8cQ5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#on average, Alice's session is shorter than that of other users\n",
        "#minimum and maximum durations of Alice's and other users' sessions are approximately the same"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6-BGX0jpmDC4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "20a920b8-6108-4a2f-ac52-83c0e7353f7c"
      },
      "cell_type": "code",
      "source": [
        "def approx(a,b):\n",
        "  c = abs(a-b)\n",
        "  d = max(a,b)\n",
        "  return c/d\n",
        "\n",
        "print(approx(1800, 1763))"
      ],
      "execution_count": 469,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.020555555555555556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FZztcuhkuAqH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "16412694-12c0-4c92-f945-1c264b326a6c"
      },
      "cell_type": "code",
      "source": [
        "bins = [-1,40, 1800]\n",
        "\n",
        "group_names = ['<=40', '>40']\n",
        "time_df['flag'] = pd.cut(time_df['seconds'], bins, labels=group_names)\n",
        "time_df['flag'].value_counts()"
      ],
      "execution_count": 470,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<=40    145084\n",
              ">40     108477\n",
              "Name: flag, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 470
        }
      ]
    },
    {
      "metadata": {
        "id": "x3TaUfqDbmsZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1dd276a8-832d-4b0e-f56e-820af42a4c4b"
      },
      "cell_type": "code",
      "source": [
        "alice_40=time_df[(time_df['target']==1) & (time_df['seconds']>=40)]\n",
        "print(alice_40.shape[0])\n",
        "alice=time_df[(time_df['target']==1)]\n",
        "print(alice.shape[0])\n",
        "# approx_same(alice.shape[0]*.25,alice_40.shape[0])"
      ],
      "execution_count": 471,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "554\n",
            "2297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nJS2172c7xf7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0b3e8433-3fcc-4101-8bbb-54cba50d528c"
      },
      "cell_type": "code",
      "source": [
        "a = 554\n",
        "b = 2297\n",
        "# c = \n",
        "print(a/b)"
      ],
      "execution_count": 472,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2411841532433609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "823zvNYmUWvv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In order to train our first model, we need to prepare the data. First of all, exclude the target variable from the training set. Now both training and test sets have the same number of columns, therefore aggregate them into one dataframe.  Thus, all transformations will be performed simultaneously on both training and test data sets. \n",
        "\n",
        "On the one hand, it leads to the fact that both data sets have one feature space (you don't have to worry that you forgot to transform a feature in some data sets). On the other hand, processing time will increase. \n",
        "For the enormously large sets it might turn out that it is impossible to transform both data sets simultaneously (and sometimes you have to split your transformations into several stages only for train/test data set).\n",
        "In our case, with this particular data set, we are going to perform all the transformations for the whole united dataframe at once, and before training the model or making predictions we will just take its appropriate part."
      ]
    },
    {
      "metadata": {
        "id": "bZ0MFWNIUWvw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Our target variable\n",
        "y_train = train_df['target']\n",
        "\n",
        "# United dataframe of the initial data \n",
        "full_df = pd.concat([train_df.drop('target', axis=1), test_df])\n",
        "\n",
        "# Index to split the training and test data sets\n",
        "idx_split = train_df.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3kSi0dsCUWv0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For the very basic model, we will use only the visited websites in the session (but we will not take into account timestamp features). The point behind this data selection is: *Alice has her favorite sites, and the more often you see these sites in the session, the higher probability that this is Alice's session, and vice versa.*\n",
        "\n",
        "Let us prepare the data, we will take only features `site1, site2, ... , site10` from the whole dataframe. Keep in mind that the missing values are replaced with zero. Here is how the first rows of the dataframe look like:"
      ]
    },
    {
      "metadata": {
        "id": "JALfhaKwEI8o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7c6e2ee8-eaab-491f-e562-40506e0d375b"
      },
      "cell_type": "code",
      "source": [
        "print(full_df.shape)"
      ],
      "execution_count": 474,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(336358, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CljOcyS3vfSI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "0638bd1c-c5fb-4015-f28d-a47ae6fba676"
      },
      "cell_type": "code",
      "source": [
        "full_df.head(2)"
      ],
      "execution_count": 475,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site1</th>\n",
              "      <th>time1</th>\n",
              "      <th>site2</th>\n",
              "      <th>time2</th>\n",
              "      <th>site3</th>\n",
              "      <th>time3</th>\n",
              "      <th>site4</th>\n",
              "      <th>time4</th>\n",
              "      <th>site5</th>\n",
              "      <th>time5</th>\n",
              "      <th>site6</th>\n",
              "      <th>time6</th>\n",
              "      <th>site7</th>\n",
              "      <th>time7</th>\n",
              "      <th>site8</th>\n",
              "      <th>time8</th>\n",
              "      <th>site9</th>\n",
              "      <th>time9</th>\n",
              "      <th>site10</th>\n",
              "      <th>time10</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>session_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21669</th>\n",
              "      <td>56</td>\n",
              "      <td>2013-01-12 08:05:57</td>\n",
              "      <td>55</td>\n",
              "      <td>2013-01-12 08:05:57</td>\n",
              "      <td>0</td>\n",
              "      <td>NaT</td>\n",
              "      <td>0</td>\n",
              "      <td>NaT</td>\n",
              "      <td>0</td>\n",
              "      <td>NaT</td>\n",
              "      <td>0</td>\n",
              "      <td>NaT</td>\n",
              "      <td>0</td>\n",
              "      <td>NaT</td>\n",
              "      <td>0</td>\n",
              "      <td>NaT</td>\n",
              "      <td>0</td>\n",
              "      <td>NaT</td>\n",
              "      <td>0</td>\n",
              "      <td>NaT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54843</th>\n",
              "      <td>56</td>\n",
              "      <td>2013-01-12 08:37:23</td>\n",
              "      <td>55</td>\n",
              "      <td>2013-01-12 08:37:23</td>\n",
              "      <td>56</td>\n",
              "      <td>2013-01-12 09:07:07</td>\n",
              "      <td>55</td>\n",
              "      <td>2013-01-12 09:07:09</td>\n",
              "      <td>0</td>\n",
              "      <td>NaT</td>\n",
              "      <td>0</td>\n",
              "      <td>NaT</td>\n",
              "      <td>0</td>\n",
              "      <td>NaT</td>\n",
              "      <td>0</td>\n",
              "      <td>NaT</td>\n",
              "      <td>0</td>\n",
              "      <td>NaT</td>\n",
              "      <td>0</td>\n",
              "      <td>NaT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            site1               time1  site2               time2  site3  \\\n",
              "session_id                                                                \n",
              "21669          56 2013-01-12 08:05:57     55 2013-01-12 08:05:57      0   \n",
              "54843          56 2013-01-12 08:37:23     55 2013-01-12 08:37:23     56   \n",
              "\n",
              "                         time3  site4               time4  site5 time5  site6  \\\n",
              "session_id                                                                      \n",
              "21669                      NaT      0                 NaT      0   NaT      0   \n",
              "54843      2013-01-12 09:07:07     55 2013-01-12 09:07:09      0   NaT      0   \n",
              "\n",
              "           time6  site7 time7  site8 time8  site9 time9  site10 time10  \n",
              "session_id                                                              \n",
              "21669        NaT      0   NaT      0   NaT      0   NaT       0    NaT  \n",
              "54843        NaT      0   NaT      0   NaT      0   NaT       0    NaT  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 475
        }
      ]
    },
    {
      "metadata": {
        "id": "9y4xaLAPUWv2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "44ace2a5-519e-46b1-d2f9-0f8af1dd6d9f"
      },
      "cell_type": "code",
      "source": [
        "# Dataframe with indices of visited websites in session\n",
        "full_sites = full_df[sites]\n",
        "full_sites.head()"
      ],
      "execution_count": 476,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site1</th>\n",
              "      <th>site2</th>\n",
              "      <th>site3</th>\n",
              "      <th>site4</th>\n",
              "      <th>site5</th>\n",
              "      <th>site6</th>\n",
              "      <th>site7</th>\n",
              "      <th>site8</th>\n",
              "      <th>site9</th>\n",
              "      <th>site10</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>session_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21669</th>\n",
              "      <td>56</td>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54843</th>\n",
              "      <td>56</td>\n",
              "      <td>55</td>\n",
              "      <td>56</td>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77292</th>\n",
              "      <td>946</td>\n",
              "      <td>946</td>\n",
              "      <td>951</td>\n",
              "      <td>946</td>\n",
              "      <td>946</td>\n",
              "      <td>945</td>\n",
              "      <td>948</td>\n",
              "      <td>784</td>\n",
              "      <td>949</td>\n",
              "      <td>946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114021</th>\n",
              "      <td>945</td>\n",
              "      <td>948</td>\n",
              "      <td>949</td>\n",
              "      <td>948</td>\n",
              "      <td>945</td>\n",
              "      <td>946</td>\n",
              "      <td>947</td>\n",
              "      <td>945</td>\n",
              "      <td>946</td>\n",
              "      <td>946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146670</th>\n",
              "      <td>947</td>\n",
              "      <td>950</td>\n",
              "      <td>948</td>\n",
              "      <td>947</td>\n",
              "      <td>950</td>\n",
              "      <td>952</td>\n",
              "      <td>946</td>\n",
              "      <td>951</td>\n",
              "      <td>946</td>\n",
              "      <td>947</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            site1  site2  site3  site4  site5  site6  site7  site8  site9  \\\n",
              "session_id                                                                  \n",
              "21669          56     55      0      0      0      0      0      0      0   \n",
              "54843          56     55     56     55      0      0      0      0      0   \n",
              "77292         946    946    951    946    946    945    948    784    949   \n",
              "114021        945    948    949    948    945    946    947    945    946   \n",
              "146670        947    950    948    947    950    952    946    951    946   \n",
              "\n",
              "            site10  \n",
              "session_id          \n",
              "21669            0  \n",
              "54843            0  \n",
              "77292          946  \n",
              "114021         946  \n",
              "146670         947  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 476
        }
      ]
    },
    {
      "metadata": {
        "id": "91q5gTdBUWv7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Sessions are sequences of website indices, and data in this representation is useless for machine learning method (just think, what happens if we switched all ids of all websites). \n",
        "\n",
        "According to our hypothesis (Alice has favorite websites), we need to transform this dataframe so each website has a corresponding feature (column) and its value is equal to number of this website visits in the session. It can be done in two lines:"
      ]
    },
    {
      "metadata": {
        "id": "Ka6KVQRNUWv9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8110ccef-9c04-48f1-e3b8-4f1b13304459"
      },
      "cell_type": "code",
      "source": [
        "# sequence of indices\n",
        "sites_flatten = full_sites.values.flatten()\n",
        "print(sites_flatten)\n",
        "print(sites_flatten.shape)\n",
        "\n",
        "# and the matrix we are looking for \n",
        "# (make sure you understand which of the `csr_matrix` constructors is used here)\n",
        "# a further toy example will help you with it\n",
        "full_sites_sparse = csr_matrix(([1] * sites_flatten.shape[0], sites_flatten,\n",
        "                                range(0, sites_flatten.shape[0]  + 10, 10)))[:, 1:]"
      ],
      "execution_count": 477,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  56   55    0 ... 1098 1098 1098]\n",
            "(3363580,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ehh1RDXqUWwA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2b50a7cc-b423-4959-fa60-87319deb3ec3"
      },
      "cell_type": "code",
      "source": [
        "full_sites_sparse.shape"
      ],
      "execution_count": 478,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(336358, 48371)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 478
        }
      ]
    },
    {
      "metadata": {
        "id": "qsRInImXUWwI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "63b29fd9-dcf3-4516-9845-01d9a663c310"
      },
      "cell_type": "code",
      "source": [
        "336358*48371/1e9"
      ],
      "execution_count": 479,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16.269972818"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 479
        }
      ]
    },
    {
      "metadata": {
        "id": "feYsiYdjUWwT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If you understand what just happened here, then you can skip the next passage (perhaps, you can handle logistic regression too?), If not, then let us figure it out.\n",
        "\n",
        "### Important detour #1: Sparse Matrices\n",
        "\n",
        "Let us estimate how much memory it will require to store our data in the example above. Our united dataframe contains 336 thousand samples of 48 thousand integer features in each. It's easy to calculate the required amount of memory, roughly:\n",
        "\n",
        "$$336\\ K * 48\\ K * 8\\ bytes \\approx 16* 10^9 * 8\\ bytes = 128\\ GB,$$\n",
        "\n",
        "(that's the [exact](http://www.wolframalpha.com/input/?i=336358*48371*8+bytes) value). Obviously, ordinary mortals have no such volumes (strictly speaking, Python may allow you to create such a matrix, but it will not be easy to do anything with it). The interesting fact is that most of the elements of our matrix are zeros. If we count non-zero elements, then it will be about 1.8 million, i.Ðµ. slightly more than 10% of all matrix elements. Such a matrix, where most elements are zeros, is called sparse, and the ratio between the number of zero elements and the total number of elements is called the sparseness of the matrix.\n",
        "\n",
        "For the work with such matrices you can use `scipy.sparse` library, check [documentation](https://docs.scipy.org/doc/scipy-0.18.1/reference/sparse.html) to understand what possible types of sparse matrices are, how to work with them and in which cases their usage is most effective. You can learn how they are arranged, for example, in Wikipedia [article](https://en.wikipedia.org/wiki/Sparse_matrix).\n",
        "Note, that a sparse matrix contains only non-zero elements, and you can get the allocated memory size like this (significant memory savings are obvious):"
      ]
    },
    {
      "metadata": {
        "id": "VAPmj45pUWwW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bc71741d-5560-4ec0-e51c-4af7a35fb6ce"
      },
      "cell_type": "code",
      "source": [
        "# How much memory does a sparse matrix occupy?\n",
        "print('{0} elements * {1} bytes = {2} bytes'.format(full_sites_sparse.count_nonzero(), 8, \n",
        "                                                    full_sites_sparse.count_nonzero() * 8))\n",
        "# Or just like this:\n",
        "print('sparse_matrix_size = {0} bytes'.format(full_sites_sparse.data.nbytes))"
      ],
      "execution_count": 480,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1866898 elements * 8 bytes = 14935184 bytes\n",
            "sparse_matrix_size = 14935184 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-FzvD7sKUWwd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let us explore how the matrix with the websites has been formed using a mini example. Suppose we have the following table with user sessions:\n",
        "\n",
        "| id | site1 | site2 | site3 |\n",
        "|---|---|---|---|\n",
        "| 1 | 1 | 0 | 0 |\n",
        "| 2 | 1 | 3 | 1 |\n",
        "| 3 | 2 | 3 | 4 |\n",
        "\n",
        "There are 3 sessions, and no more than 3 websites in each. Users visited four different sites in total (there are numbers from 1 to 4 in the table cells). And let us assume that the mapping is:\n",
        "\n",
        " 1. vk.com\n",
        " 2. habrahabr.ru \n",
        " 3. yandex.ru\n",
        " 4. ods.ai\n",
        "\n",
        "If the user has visited less than 3 websites during the session, the last few values will be zero. We want to convert the original dataframe in a way that each session has a corresponding row which shows the number of visits to each particular site. I.e. we want to transform the previous table into the following form:\n",
        "\n",
        "| id | vk.com | habrahabr.ru | yandex.ru | ods.ai |\n",
        "|---|---|---|---|---|\n",
        "| 1 | 1 | 0 | 0 | 0 |\n",
        "| 2 | 2 | 0 | 1 | 0 |\n",
        "| 3 | 0 | 1 | 1 | 1 |\n",
        "\n",
        "\n",
        "To do this, use the constructor: `csr_matrix ((data, indices, indptr))` and create a frequency table (see examples, code and comments on the links above to see how it works). Here we set all the parameters explicitly for greater clarity:"
      ]
    },
    {
      "metadata": {
        "id": "XeMigc1Ih3aY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "27b8b629-afe2-4280-c772-15cd0daace06"
      },
      "cell_type": "code",
      "source": [
        "data = [1] * 9\n",
        "print(data)"
      ],
      "execution_count": 481,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "o8kA460eUWwe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0612c485-6bd5-4cba-c43e-6f6fbe5116fe"
      },
      "cell_type": "code",
      "source": [
        "# data, create the list of ones, length of which equal to the number of elements in the initial dataframe (9)\n",
        "# By summing the number of ones in the cell, we get the frequency,\n",
        "# number of visits to a particular site per session\n",
        "data = [1] * 9\n",
        "\n",
        "# To do this, you need to correctly distribute the ones in cells\n",
        "# Indices - website ids, i.e. columns of a new matrix. We will sum ones up grouping them by sessions (ids)\n",
        "indices = [1, 0, 0, 1, 3, 1, 2, 3, 4]\n",
        "\n",
        "# Indices for the division into rows (sessions)\n",
        "# For example, line 0 is the elements between the indices [0; 3) - the rightmost value is not included\n",
        "# Line 1 is the elements between the indices [3; 6)\n",
        "# Line 2 is the elements between the indices [6; 9) \n",
        "indptr = [0, 3, 6, 9]\n",
        "\n",
        "# Aggregate these three variables into a tuple and compose a matrix\n",
        "# To display this matrix on the screen transform it into the usual \"dense\" matrix\n",
        "csr_matrix((data, indices, indptr)).todense()"
      ],
      "execution_count": 482,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[2, 1, 0, 0, 0],\n",
              "        [0, 2, 0, 1, 0],\n",
              "        [0, 0, 1, 1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 482
        }
      ]
    },
    {
      "metadata": {
        "id": "cP-UdhDFUWwk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As you might have noticed, there are not four columns in the resulting matrix (corresponding to number of different websites) but five. A zero column has been added, which indicates if the session was shorter (in our mini example we took sessions of three). This column is excessive and should be removed from the dataframe (do that yourself).\n",
        "\n",
        "##### 3. What is the sparseness of the matrix in our small example?\n",
        "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai, pinned thread __#a2_q3__*\n",
        "\n",
        "- 42%\n",
        "- 47%\n",
        "- 50%\n",
        "- 53%"
      ]
    },
    {
      "metadata": {
        "id": "0dp0bZDiUWwm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Your code is here\n",
        "# non_zero = np.count_nonzero(full_sites_sparse.toarray())\n",
        "# total_val = np.product(X.shape)\n",
        "# test_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mk1_5zQjUWwq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Another benefit of using sparse matrices is that there are special implementations of both matrix operations and machine learning algorithms for them, which sometimes allows to significantly accelerate operations due to the data structure peculiarities. This applies to logistic regression as well. Now everything is ready to build our first model.\n",
        "\n",
        "### 3. Training the first model\n",
        "\n",
        "So, we have an algorithm and data for it. Let us build our first model, using [logistic regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) implementation from ` Sklearn` with default parameters. We will use the first 90% of the data for training (the training data set is sorted by time), and the remaining 10% for validation. Let's write a simple function that returns the quality of the model and then train our first classifier:"
      ]
    },
    {
      "metadata": {
        "id": "mR0rBybxUWwr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_auc_lr_valid(X, y, C=1.0, seed=17, ratio = 0.9):\n",
        "    # Split the data into the training and validation sets\n",
        "    idx = int(round(X.shape[0] * ratio))\n",
        "    # Classifier training\n",
        "    lr = LogisticRegression(C=C, random_state=seed, solver='liblinear').fit(X[:idx, :], y[:idx])\n",
        "    # Prediction for validation set\n",
        "    y_pred = lr.predict_proba(X[idx:, :])[:, 1]\n",
        "    # Calculate the quality\n",
        "    score = roc_auc_score(y[idx:], y_pred)\n",
        "    \n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c74FzcdPUWww",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "72461d92-05e4-4f5a-b948-ec6009b918f4"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Select the training set from the united dataframe (where we have the answers)\n",
        "X_train = full_sites_sparse[:idx_split, :]\n",
        "\n",
        "# Calculate metric on the validation set\n",
        "print(get_auc_lr_valid(X_train, y_train))"
      ],
      "execution_count": 485,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9195244077552184\n",
            "CPU times: user 7.36 s, sys: 25 ms, total: 7.39 s\n",
            "Wall time: 7.39 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wAjMAdeFUWw2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The first model demonstrated the quality  of 0.92 on the validation set. Let's take it as the first baseline and starting point. To make a prediction on the test data set **we need to train the model again on the entire training data set** (until this moment, our model used only part of the data for training), which will increase its generalizing ability:"
      ]
    },
    {
      "metadata": {
        "id": "BVE9I3gpUWw3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Function for writing predictions to a file\n",
        "def write_to_submission_file(predicted_labels, out_file,\n",
        "                             target='target', index_label=\"session_id\"):\n",
        "    predicted_df = pd.DataFrame(predicted_labels,\n",
        "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
        "                                columns=[target])\n",
        "    predicted_df.to_csv(out_file, index_label=index_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H0zmoR5oUWw-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train the model on the whole training data set\n",
        "# Use random_state=17 for repeatability\n",
        "# Parameter C=1 by default, but here we set it explicitly\n",
        "lr = LogisticRegression(C=1.0, random_state=17, solver='liblinear').fit(X_train, y_train)\n",
        "\n",
        "# Make a prediction for test data set\n",
        "X_test = full_sites_sparse[idx_split:,:]\n",
        "y_test = lr.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Write it to the file which could be submitted\n",
        "write_to_submission_file(y_test, 'baseline_1.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x0-ru79GUWxD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If you follow these steps and upload the answer to the competition [page](https://inclass.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2), you will get `ROC AUC = 0.90812` on the public leaderboard (\"A2 baseline 1\").\n",
        "\n",
        "### 4. Model Improvement: Feature Engineering\n",
        "\n",
        "Now we are going to try to improve the quality of our model by adding new features to the data. But first, answer the following question:\n",
        "\n",
        "##### 4. What years are present in the training and test datasets, if united?\n",
        "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai, pinned thread __#a2_q4__*\n",
        "\n",
        "- 13 and 14\n",
        "- 2012 and 2013\n",
        "- 2013 and 2014\n",
        "- 2014 and 2015"
      ]
    },
    {
      "metadata": {
        "id": "Xh6s8YGHUWxF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "41ab456a-5e89-408c-b93b-bdd69f24090a"
      },
      "cell_type": "code",
      "source": [
        "# Your code is here\n",
        "print(train_df.shape)\n",
        "print(time_df.shape)\n",
        "# time_df\n",
        "time_test_df['target'] = time_test_df.apply(lambda x: 0)\n"
      ],
      "execution_count": 488,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(253561, 21)\n",
            "(253561, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SuezHS3192HS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "3478ad33-efff-4324-9754-63b3fdec5982"
      },
      "cell_type": "code",
      "source": [
        "print(time_test_df.head(2))"
      ],
      "execution_count": 489,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                           min                 max  seconds  target\n",
            "session_id                                                         \n",
            "1          2014-10-04 11:19:53 2014-10-04 11:20:00      7.0     NaN\n",
            "2          2014-07-03 11:00:28 2014-07-03 11:01:53     85.0     NaN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6znN4Gux99B6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "12026719-39bd-41ee-aab4-ff49ce244acc"
      },
      "cell_type": "code",
      "source": [
        "time_test_df.isnull().sum()"
      ],
      "execution_count": 490,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "min            0\n",
              "max            0\n",
              "seconds        0\n",
              "target     82797\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 490
        }
      ]
    },
    {
      "metadata": {
        "id": "ObqIYC3j-Lc5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "time_test_df['target'].fillna(0, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A1TaBtFi-cUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "3d43aba5-d74a-4579-ee16-d4d50ffbfabf"
      },
      "cell_type": "code",
      "source": [
        "#join two datasets\n",
        "final_train_test_df = pd.concat([time_df, time_test_df])\n",
        "print(time_df.shape)\n",
        "print(time_test_df.shape)\n",
        "print(final_train_test_df.shape)"
      ],
      "execution_count": 492,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(253561, 5)\n",
            "(82797, 4)\n",
            "(336358, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "szP7aNlB_YIo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "final_train_test_df['year_max'] = pd.DatetimeIndex(final_train_test_df['max']).year\n",
        "final_train_test_df['year_min'] = pd.DatetimeIndex(final_train_test_df['min']).year"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QV7IwYq9BkFK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "856c7454-020e-4535-c69c-8ea2b880e32b"
      },
      "cell_type": "code",
      "source": [
        "final_train_test_df.head(3)"
      ],
      "execution_count": 494,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>flag</th>\n",
              "      <th>max</th>\n",
              "      <th>min</th>\n",
              "      <th>seconds</th>\n",
              "      <th>target</th>\n",
              "      <th>year_max</th>\n",
              "      <th>year_min</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>session_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21669</th>\n",
              "      <td>&lt;=40</td>\n",
              "      <td>2013-01-12 08:05:57</td>\n",
              "      <td>2013-01-12 08:05:57</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2013</td>\n",
              "      <td>2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54843</th>\n",
              "      <td>&gt;40</td>\n",
              "      <td>2013-01-12 09:07:09</td>\n",
              "      <td>2013-01-12 08:37:23</td>\n",
              "      <td>1786.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2013</td>\n",
              "      <td>2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77292</th>\n",
              "      <td>&lt;=40</td>\n",
              "      <td>2013-01-12 08:50:17</td>\n",
              "      <td>2013-01-12 08:50:13</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2013</td>\n",
              "      <td>2013</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            flag                 max                 min  seconds  target  \\\n",
              "session_id                                                                  \n",
              "21669       <=40 2013-01-12 08:05:57 2013-01-12 08:05:57      0.0     0.0   \n",
              "54843        >40 2013-01-12 09:07:09 2013-01-12 08:37:23   1786.0     0.0   \n",
              "77292       <=40 2013-01-12 08:50:17 2013-01-12 08:50:13      4.0     0.0   \n",
              "\n",
              "            year_max  year_min  \n",
              "session_id                      \n",
              "21669           2013      2013  \n",
              "54843           2013      2013  \n",
              "77292           2013      2013  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 494
        }
      ]
    },
    {
      "metadata": {
        "id": "0x-MSjjNDqQ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "334313b0-186f-464a-bbca-275c58b28b5f"
      },
      "cell_type": "code",
      "source": [
        "print(final_train_test_df['year_max'].unique())\n",
        "print(final_train_test_df['year_min'].unique())"
      ],
      "execution_count": 495,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2013 2014]\n",
            "[2013 2014]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fc5ZKojaUWxJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a feature that will be a number in YYYYMM format from the date when the session was held, for example 201407 -- year 2014 and 7th month. Thus, we will take into account the monthly [linear trend](http://people.duke.edu/~rnau/411trend.htm) for the entire period of the data provided."
      ]
    },
    {
      "metadata": {
        "id": "d4HL6rNBUWxK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dataframe for new features\n",
        "full_new_feat = pd.DataFrame(index=full_df.index)\n",
        "\n",
        "# Add start_month feature\n",
        "full_new_feat['start_month'] = full_df['time1'].apply(lambda ts: \n",
        "                                                      100 * ts.year + ts.month).astype('float64')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ChyJlWjbEwsa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "3f715376-85b7-4ba2-e9fa-51f0680491d1"
      },
      "cell_type": "code",
      "source": [
        "full_new_feat.head(2)"
      ],
      "execution_count": 497,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start_month</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>session_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21669</th>\n",
              "      <td>201301.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54843</th>\n",
              "      <td>201301.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            start_month\n",
              "session_id             \n",
              "21669          201301.0\n",
              "54843          201301.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 497
        }
      ]
    },
    {
      "metadata": {
        "id": "787KdIo5UWxQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### 5. Plot the graph of the number of Alice sessions versus the new feature, start_month. Choose the correct statement:\n",
        "\n",
        "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai, pinned thread __#a2_q5__*\n",
        "\n",
        "- Alice wasn't online at all for the entire period\n",
        "- From the beginning of 2013 to mid-2014, the number of Alice's sessions per month decreased\n",
        "- The number of Alice's sessions per month is generally constant for the entire period\n",
        "- From the beginning of 2013 to mid-2014, the number of Alice's sessions per month increased\n",
        "\n",
        "*Hint: the graph will be more explicit if you treat `start_month` as a categorical ordinal variable*."
      ]
    },
    {
      "metadata": {
        "id": "iyYw1B7aJpXb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "alice_ids = train_df[train_df['target'] == 1].reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lxDkEnrBJ7xL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "1f944176-6e51-4337-c93e-e81a1a886fa1"
      },
      "cell_type": "code",
      "source": [
        "alice_ids.head(3)"
      ],
      "execution_count": 499,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>session_id</th>\n",
              "      <th>site1</th>\n",
              "      <th>time1</th>\n",
              "      <th>site2</th>\n",
              "      <th>time2</th>\n",
              "      <th>site3</th>\n",
              "      <th>time3</th>\n",
              "      <th>site4</th>\n",
              "      <th>time4</th>\n",
              "      <th>site5</th>\n",
              "      <th>...</th>\n",
              "      <th>time6</th>\n",
              "      <th>site7</th>\n",
              "      <th>time7</th>\n",
              "      <th>site8</th>\n",
              "      <th>time8</th>\n",
              "      <th>site9</th>\n",
              "      <th>time9</th>\n",
              "      <th>site10</th>\n",
              "      <th>time10</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>251175</td>\n",
              "      <td>270</td>\n",
              "      <td>2013-02-12 16:25:10</td>\n",
              "      <td>270</td>\n",
              "      <td>2013-02-12 16:25:11</td>\n",
              "      <td>270</td>\n",
              "      <td>2013-02-12 16:32:10</td>\n",
              "      <td>21</td>\n",
              "      <td>2013-02-12 16:32:11</td>\n",
              "      <td>21</td>\n",
              "      <td>...</td>\n",
              "      <td>2013-02-12 16:32:25</td>\n",
              "      <td>21</td>\n",
              "      <td>2013-02-12 16:32:25</td>\n",
              "      <td>7832</td>\n",
              "      <td>2013-02-12 16:32:26</td>\n",
              "      <td>30</td>\n",
              "      <td>2013-02-12 16:32:27</td>\n",
              "      <td>7832</td>\n",
              "      <td>2013-02-12 16:32:27</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>196388</td>\n",
              "      <td>29</td>\n",
              "      <td>2013-02-12 16:32:27</td>\n",
              "      <td>7832</td>\n",
              "      <td>2013-02-12 16:32:28</td>\n",
              "      <td>37</td>\n",
              "      <td>2013-02-12 16:32:29</td>\n",
              "      <td>7832</td>\n",
              "      <td>2013-02-12 16:32:34</td>\n",
              "      <td>7832</td>\n",
              "      <td>...</td>\n",
              "      <td>2013-02-12 16:32:35</td>\n",
              "      <td>7832</td>\n",
              "      <td>2013-02-12 16:32:42</td>\n",
              "      <td>29</td>\n",
              "      <td>2013-02-12 16:32:42</td>\n",
              "      <td>7832</td>\n",
              "      <td>2013-02-12 16:32:51</td>\n",
              "      <td>7832</td>\n",
              "      <td>2013-02-12 16:32:53</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>172448</td>\n",
              "      <td>29</td>\n",
              "      <td>2013-02-12 16:32:53</td>\n",
              "      <td>7832</td>\n",
              "      <td>2013-02-12 16:33:11</td>\n",
              "      <td>7832</td>\n",
              "      <td>2013-02-12 16:33:12</td>\n",
              "      <td>29</td>\n",
              "      <td>2013-02-12 16:33:13</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>2013-02-12 16:33:24</td>\n",
              "      <td>29</td>\n",
              "      <td>2013-02-12 16:33:24</td>\n",
              "      <td>7832</td>\n",
              "      <td>2013-02-12 16:33:33</td>\n",
              "      <td>29</td>\n",
              "      <td>2013-02-12 16:33:34</td>\n",
              "      <td>270</td>\n",
              "      <td>2013-02-12 16:33:46</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows Ã— 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   session_id  site1               time1  site2               time2  site3  \\\n",
              "0      251175    270 2013-02-12 16:25:10    270 2013-02-12 16:25:11    270   \n",
              "1      196388     29 2013-02-12 16:32:27   7832 2013-02-12 16:32:28     37   \n",
              "2      172448     29 2013-02-12 16:32:53   7832 2013-02-12 16:33:11   7832   \n",
              "\n",
              "                time3  site4               time4  site5   ...    \\\n",
              "0 2013-02-12 16:32:10     21 2013-02-12 16:32:11     21   ...     \n",
              "1 2013-02-12 16:32:29   7832 2013-02-12 16:32:34   7832   ...     \n",
              "2 2013-02-12 16:33:12     29 2013-02-12 16:33:13     37   ...     \n",
              "\n",
              "                time6  site7               time7  site8               time8  \\\n",
              "0 2013-02-12 16:32:25     21 2013-02-12 16:32:25   7832 2013-02-12 16:32:26   \n",
              "1 2013-02-12 16:32:35   7832 2013-02-12 16:32:42     29 2013-02-12 16:32:42   \n",
              "2 2013-02-12 16:33:24     29 2013-02-12 16:33:24   7832 2013-02-12 16:33:33   \n",
              "\n",
              "   site9               time9  site10              time10  target  \n",
              "0     30 2013-02-12 16:32:27    7832 2013-02-12 16:32:27       1  \n",
              "1   7832 2013-02-12 16:32:51    7832 2013-02-12 16:32:53       1  \n",
              "2     29 2013-02-12 16:33:34     270 2013-02-12 16:33:46       1  \n",
              "\n",
              "[3 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 499
        }
      ]
    },
    {
      "metadata": {
        "id": "P8VnFV45UWxS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "13eabdf3-6449-439d-dc18-0c3dabe1f436"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "full_new_feat_1 = full_new_feat.reset_index()\n",
        "#select the ids with alice_ids\n",
        "print(full_new_feat_1.shape)\n",
        "alice_sess_list = alice_ids['session_id'].values\n",
        "\n",
        "full_new_feat_2 = full_new_feat_1[full_new_feat_1['session_id'].isin(alice_sess_list)]  \n",
        "print(full_new_feat_2.shape)\n",
        "\n",
        "\n",
        "full_new_feat_2 = full_new_feat_2.groupby('start_month').count().reset_index()\n",
        "\n",
        "start_month = full_new_feat_2['start_month'].values\n",
        "\n",
        "session_id = full_new_feat_2['session_id'].values\n",
        "\n",
        "plt.plot(start_month, session_id, color='g')\n",
        "\n",
        "plt.xlabel('time')\n",
        "plt.ylabel('Session Count')\n",
        "plt.title('Session count vs time')\n",
        "plt.show()"
      ],
      "execution_count": 500,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(336358, 2)\n",
            "(3054, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFnCAYAAABdOssgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "qFE1sWO-UWxW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this way, we have an illustration and thoughts about the usefulness of the new feature, add it to the training sample and check the quality of the new model:"
      ]
    },
    {
      "metadata": {
        "id": "rIO-mXLyI8MS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "b6d01e3d-f4b2-40a4-985c-dbbbf2a12b37"
      },
      "cell_type": "code",
      "source": [
        "tmp = full_new_feat[['start_month']].values\n",
        "print(tmp)"
      ],
      "execution_count": 501,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[201301.]\n",
            " [201301.]\n",
            " [201301.]\n",
            " ...\n",
            " [201405.]\n",
            " [201405.]\n",
            " [201411.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x-UM5NM-SCnW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dc011b02-a818-46a7-89be-9bb0dab7a4ad"
      },
      "cell_type": "code",
      "source": [
        "idx_split"
      ],
      "execution_count": 502,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "253561"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 502
        }
      ]
    },
    {
      "metadata": {
        "id": "vaGMrz0pSeO3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "70b7016f-c834-48ce-8143-d5090c46ba30"
      },
      "cell_type": "code",
      "source": [
        "full_sites_sparse"
      ],
      "execution_count": 503,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<336358x48371 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 1866898 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 503
        }
      ]
    },
    {
      "metadata": {
        "id": "hvAweB0TUWxX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "47f3eca1-f2a8-4c53-c106-d200f68d9e60"
      },
      "cell_type": "code",
      "source": [
        "# Add the new feature to the sparse matrix\n",
        "tmp = full_new_feat[['start_month']].values\n",
        "X_train = csr_matrix(hstack([full_sites_sparse[:idx_split,:], tmp[:idx_split,:]]))\n",
        "\n",
        "# Compute the metric on the validation set\n",
        "print(get_auc_lr_valid(X_train, y_train))"
      ],
      "execution_count": 504,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7508354860175162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q4t2N_GFUWxb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The quality of the model has decreased significantly. We added a feature that definitely seemed useful to us, but its usage only worsened the model. Why did it happen?\n",
        "\n",
        "### Important detour #2: is it necessary to scale features?\n",
        "\n",
        "Here we give an intuitive reasoning (a rigorous mathematical justification for one or another aspect in linear models you can easily find on the internet). Consider the features more closely: those of them that correspond to the number of visits to a particular web-site per session vary from 0 to 10. The feature `start_month` has a completely different range: from 201301 to 201412, this means the contribution of this variable is significantly greater than the others. It would seem that problem can be avoided if we put less weight in a linear combination of attributes in this case, but in our case logistic regression with regularization is used (by default, this parameter is `C = 1`), which penalizes the model the stronger the greater its weights are. Therefore, for linear methods with regularization, it is recommended to convert features to the same scale (you can read more about the regularization, for example, [here](https://habrahabr.ru/company/ods/blog/322076/)).\n",
        "\n",
        "One way to do this is standardization: for each observation you need to subtract the average value of the feature and divide this difference by the standard deviation:\n",
        "\n",
        "$$ x^{*}_{i} = \\dfrac{x_{i} - \\mu_x}{\\sigma_x}$$\n",
        "\n",
        "The following practical tips can be given:\n",
        "- It is recommended to scale features if they have essentially different ranges or different units of measurement (for example, the country's population is indicated in units, and the country's GNP in trillions)\n",
        "- Scale features if you do not have a reason/expert opinion to give a greater weight to any of them\n",
        "- Scaling can be excessive if the ranges of some of your features differ from each other, but they are in the same system of units (for example, the proportion of middle-aged people and people over 80 among the entire population)\n",
        "- If you want to get an interpreted model, then build a model without regularization and scaling (most likely, its quality will be worse)\n",
        "- Binary features (which take only values of 0 or 1) are usually left without conversion, (but)\n",
        "- If the quality of the model is crucial, try different options and select one where the quality is better\n",
        "\n",
        "Getting back to `start_month`, let us rescale the new feature and train the model again. This time the quality has increased:"
      ]
    },
    {
      "metadata": {
        "id": "KofLV8ccYba_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "8a29e0ae-758d-471b-8cbf-0057fe485fcb"
      },
      "cell_type": "code",
      "source": [
        "full_new_feat.head(2)"
      ],
      "execution_count": 505,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start_month</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>session_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21669</th>\n",
              "      <td>201301.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54843</th>\n",
              "      <td>201301.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            start_month\n",
              "session_id             \n",
              "21669          201301.0\n",
              "54843          201301.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 505
        }
      ]
    },
    {
      "metadata": {
        "id": "Q8Ee0dIiUWxk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b05ba741-8876-42e4-a099-0937c5e0258d"
      },
      "cell_type": "code",
      "source": [
        "# Add the new standardized feature to the sparse matrix\n",
        "tmp = StandardScaler().fit_transform(full_new_feat[['start_month']])\n",
        "X_train = csr_matrix(hstack([full_sites_sparse[:idx_split,:], tmp[:idx_split,:]]))\n",
        "\n",
        "# Compute metric on the validation set\n",
        "print(get_auc_lr_valid(X_train, y_train))"
      ],
      "execution_count": 506,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9196990680356892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hBZ-kXFFUWxq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### 6. Add to the training set a new feature \"n_unique_sites\" â€“ the number of the unique web-sites in a session. Calculate how the quality on the validation set has changed\n",
        "\n",
        "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai, pinned thread __#a2_q6__*\n",
        "\n",
        "- It has decreased. It is better not to add a new feature.\n",
        "- It has not changed.\n",
        "- It has decreased. The new feature should be scaled.\n",
        "- I am confused, and I do not know if it's necessary to scale a new feature.\n",
        "\n",
        "*Tips: use the nunique() function from `pandas`. Do not forget to include the start_month in the set. Will you scale a new feature? Why?*"
      ]
    },
    {
      "metadata": {
        "id": "cLKNR2W1bkHT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "f6dcbe0c-4a06-4fd2-d35c-fa0e123fb68f"
      },
      "cell_type": "code",
      "source": [
        "full_new_feat.head(2)"
      ],
      "execution_count": 507,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start_month</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>session_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21669</th>\n",
              "      <td>201301.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54843</th>\n",
              "      <td>201301.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            start_month\n",
              "session_id             \n",
              "21669          201301.0\n",
              "54843          201301.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 507
        }
      ]
    },
    {
      "metadata": {
        "id": "vHMRfi6uuOu4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "2cc79bfe-671a-4a9b-c165-536aad25338f"
      },
      "cell_type": "code",
      "source": [
        "unique_count[:3] #print few"
      ],
      "execution_count": 508,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2],\n",
              "       [2],\n",
              "       [6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 508
        }
      ]
    },
    {
      "metadata": {
        "id": "wpoDGkpy2sLo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unique_count_1  = pd.DataFrame(index=full_df.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MCq1jOTY3N_g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "991c0a34-d086-4ba1-ec38-c44727c33ff2"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#Getting Unique Counts\n",
        "unique_count = []\n",
        "for row in full_sites.values:\n",
        "    unique = np.unique (row)\n",
        "    \n",
        "    if 0 in unique:\n",
        "        unique_count.append(len(unique) - 1)\n",
        "    else:\n",
        "        unique_count.append(len(unique))\n",
        "unique_count = np.array(unique_count).reshape(-1,1)\n"
      ],
      "execution_count": 510,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4.83 s, sys: 11.1 ms, total: 4.84 s\n",
            "Wall time: 4.83 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s2Yrx2JF32IV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unique_count_1 = pd.DataFrame(unique_count, index = full_df.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7gUJDrQU03WY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "full_new_feat['n_unique_sites'] = unique_count_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2BeYTlA21Bbj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d08c309f-725e-46eb-dc39-3a43132adfca"
      },
      "cell_type": "code",
      "source": [
        "full_new_feat.shape"
      ],
      "execution_count": 513,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(336358, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 513
        }
      ]
    },
    {
      "metadata": {
        "id": "Ah8MKieT1EIA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "efdae508-9102-4bed-aa64-bc081e79b65d"
      },
      "cell_type": "code",
      "source": [
        "full_new_feat.head(2)"
      ],
      "execution_count": 514,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start_month</th>\n",
              "      <th>n_unique_sites</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>session_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21669</th>\n",
              "      <td>201301.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54843</th>\n",
              "      <td>201301.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            start_month  n_unique_sites\n",
              "session_id                             \n",
              "21669          201301.0               2\n",
              "54843          201301.0               2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 514
        }
      ]
    },
    {
      "metadata": {
        "id": "dWXm9e3LUWxr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "995e57ae-a519-4a21-eaa7-10c7c507c44f"
      },
      "cell_type": "code",
      "source": [
        "# Your code is here\n",
        "\n",
        "\n",
        "# Add the new standardized feature to the sparse matrix\n",
        "tmp = StandardScaler().fit_transform(full_new_feat[['start_month', 'n_unique_sites']])\n",
        "X_train = csr_matrix(hstack([full_sites_sparse[:idx_split,:], tmp[:idx_split,:]]))\n",
        "\n",
        "# Compute metric on the validation set\n",
        "print(get_auc_lr_valid(X_train, y_train))\n"
      ],
      "execution_count": 515,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9161731796685169\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DFiQw2U9UWxx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So, the new feature has slightly decreased the quality, so we will not use it. Nevertheless, do not rush to throw features out because they haven't performed well. They can be useful in a combination with other features (for example, when a new feature is a ratio or a product of two others).\n",
        "\n",
        "#####  7. Add two new features: start_hour and morning. Calculate the metric. Which of these features gives an improvement?\n",
        "\n",
        "The `start_hour` feature is the hour at which the session started (from 0 to 23), and the binary feature `morning` is equal to 1 if the session started in the morning and 0 if the session started later (we assume that morning means `start_hour` is equal to 11 or less).\n",
        "\n",
        "Will you scale the new features? Make your assumptions and test them in practice.\n",
        "\n",
        "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai, pinned thread __#a2_q7__*\n",
        "\n",
        "- None of the features gave an improvement :(\n",
        "- `start_hour` feature gave an improvement, and `morning` did not\n",
        "- `morning` feature gave an improvement, and `start_hour` did not\n",
        "- Both features gave an improvement\n",
        "\n",
        "*Tip: find suitable functions for working with time series data in [documentation](http://pandas.pydata.org/pandas-docs/stable/api.html). Do not forget to include the `start_month` feature.*"
      ]
    },
    {
      "metadata": {
        "id": "sA705x16UWxy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Your code is here\n",
        "\n",
        "full_new_feat['start_hour']  =  full_df['time1'].apply(lambda ts: ts.hour) \n",
        "full_new_feat['morning']  = full_new_feat['start_hour'].apply(lambda x: 1 if ((x >= 7) & (x <= 11)) else 0 )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ljac5cG3Lcwt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "80d6ad52-b890-489c-b76a-63797a3634c1"
      },
      "cell_type": "code",
      "source": [
        "full_new_feat.head(2)"
      ],
      "execution_count": 517,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start_month</th>\n",
              "      <th>n_unique_sites</th>\n",
              "      <th>start_hour</th>\n",
              "      <th>morning</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>session_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21669</th>\n",
              "      <td>201301.0</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54843</th>\n",
              "      <td>201301.0</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            start_month  n_unique_sites  start_hour  morning\n",
              "session_id                                                  \n",
              "21669          201301.0               2           8        1\n",
              "54843          201301.0               2           8        1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 517
        }
      ]
    },
    {
      "metadata": {
        "id": "I6na7lPiLnF1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "40d44c12-e4aa-4a62-c77b-5a74090b6e5e"
      },
      "cell_type": "code",
      "source": [
        "# Add the new standardized feature to the sparse matrix\n",
        "tmp = StandardScaler().fit_transform(full_new_feat[['start_month', 'n_unique_sites', 'start_hour','morning']])\n",
        "X_train = csr_matrix(hstack([full_sites_sparse[:idx_split,:], tmp[:idx_split,:]]))\n",
        "\n",
        "# Compute metric on the validation set\n",
        "print(get_auc_lr_valid(X_train, y_train))"
      ],
      "execution_count": 518,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9559379060813782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rCU_HWh3UWx1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5. Regularization and Parameter Tuning\n",
        "\n",
        "We have introduced features that improve the quality of our model in comparison with the first baseline. Can we do even better? After we have changed the training and test sets, it almost always makes sense to search for the optimal hyperparameters - the parameters of the model that do not change during training.\n",
        "\n",
        "For example, in week 3, you learned that, in decision trees, the depth of the tree is a hyperparameter, but the feature by which splitting occurs and its threshold is not. \n",
        "\n",
        "In the logistic regression that we use, the weights of each feature are changing, and we find their optimal values during training; meanwhile, the regularization parameter remains constant. This is the hyperparameter that we are going to optimize now.\n",
        "\n",
        "Calculate the quality on a validation set with a regularization parameter, which is equal to 1 by default:"
      ]
    },
    {
      "metadata": {
        "id": "8B6ZGW_7UWx2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "48ae63fa-504d-4606-c798-f8db0e50be6b"
      },
      "cell_type": "code",
      "source": [
        "# Compose the training set\n",
        "tmp_scaled = StandardScaler().fit_transform(full_new_feat[['start_month', \n",
        "                                                           'start_hour', \n",
        "                                                           'morning']])\n",
        "X_train = csr_matrix(hstack([full_sites_sparse[:idx_split,:], \n",
        "                             tmp_scaled[:idx_split,:]]))\n",
        "\n",
        "# Capture the quality with default parameters\n",
        "score_C_1 = get_auc_lr_valid(X_train, y_train)\n",
        "print(score_C_1)"
      ],
      "execution_count": 519,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9591502513175755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CjAQPFpQUWx5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will try to beat this result by optimizing the regularization parameter. We will take a list of possible values of C and calculate the quality metric on the validation set for each of C-values:"
      ]
    },
    {
      "metadata": {
        "id": "sVr0HasoUWx6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3508ff5d-a8be-4204-faf1-c645265ba51e"
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# List of possible C-values\n",
        "Cs = np.logspace(-3, 1, 10)\n",
        "scores = []\n",
        "for C in tqdm(Cs):\n",
        "    scores.append(get_auc_lr_valid(X_train, y_train, C=C))"
      ],
      "execution_count": 520,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:56<00:00, 10.47s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZE4PSslKUWx8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Plot the graph of the quality metric (AUC-ROC) versus the value of the regularization parameter. The value of quality metric corresponding to the default value of C=1 is represented by a horizontal dotted line:"
      ]
    },
    {
      "metadata": {
        "id": "KcJLoTviUWyB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "b74e58ed-d34a-4cc4-c233-0581e0322f48"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(Cs, scores, 'ro-')\n",
        "plt.xscale('log')\n",
        "plt.xlabel('C')\n",
        "plt.ylabel('AUC-ROC')\n",
        "plt.title('Regularization Parameter Tuning')\n",
        "# horizontal line -- model quality with default C value\n",
        "plt.axhline(y=score_C_1, linewidth=.5, color='b', linestyle='dashed') \n",
        "plt.show()"
      ],
      "execution_count": 521,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFrCAYAAADIJBAiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "bvQLtGX8UWyD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### 8. What is the value of parameter C (if rounded to 2 decimals) that corresponds to the highest model quality?\n",
        "\n",
        "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai, pinned thread __#a2_q8__*\n",
        "\n",
        "- 0.17\n",
        "- 0.46\n",
        "- 1.29\n",
        "- 3.14"
      ]
    },
    {
      "metadata": {
        "id": "VvH0U4eDUWyF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Your code is here\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ucwP1CtPUWyK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For the last task in this assignment: train the model using the optimal regularization parameter you found (do not round up to two digits like in the last question). If you do everything correctly and submit your solution, you should see `ROC AUC = 0.92784` on the public leaderboard (\"A2 baseline 2\"):"
      ]
    },
    {
      "metadata": {
        "id": "f7_8uNRWUWyK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "0d586ef0-9d3d-4d64-8427-93c7fe0bbc91"
      },
      "cell_type": "code",
      "source": [
        "# Prepare the training and test data\n",
        "tmp_scaled = StandardScaler().fit_transform(full_new_feat[['start_month', 'start_hour', \n",
        "                                                           'morning']])\n",
        "X_train = csr_matrix(hstack([full_sites_sparse[:idx_split,:], \n",
        "                             tmp_scaled[:idx_split,:]]))\n",
        "X_test = csr_matrix(hstack([full_sites_sparse[idx_split:,:], \n",
        "                            tmp_scaled[idx_split:,:]]))\n",
        "\n",
        "# Train the model on the whole training data set using optimal regularization parameter\n",
        "lr = LogisticRegression(C=C, random_state=17, solver='liblinear').fit(X_train, y_train)\n",
        "\n",
        "# with C = 0.09 -- 0.92718(LB)\n",
        "# Make a prediction for the test set\n",
        "y_test = lr.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Write it to the submission file\n",
        "write_to_submission_file(y_test, 'baseline_2.csv')"
      ],
      "execution_count": 522,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Cx40lQT4uJzm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit, cross_val_score, GridSearchCV\n",
        "time_split = TimeSeriesSplit(n_splits=10)\n",
        "\n",
        "[(el[0].shape, el[1].shape) for el in time_split.split(X_train)]\n",
        "\n",
        "logit = LogisticRegression(C=1, random_state=17, solver='liblinear')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x0JL_fK2vo9N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "53416e50-204a-453e-8d92-390e4aa1bdfa"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "cv_scores = cross_val_score(logit, X_train, y_train, cv=time_split, \n",
        "                            scoring='roc_auc', n_jobs=1) # hangs with n_jobs > 1, and locally this runs much faster"
      ],
      "execution_count": 524,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 36.7 s, sys: 90.9 ms, total: 36.8 s\n",
            "Wall time: 36.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0DR2tRC4wNgS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "abac36f0-15ff-482c-970c-a7e3a0d4175d"
      },
      "cell_type": "code",
      "source": [
        "cv_scores, cv_scores.mean()"
      ],
      "execution_count": 525,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.80969538, 0.74049299, 0.94992278, 0.97277799, 0.89898102,\n",
              "        0.95081267, 0.9498438 , 0.92869503, 0.9601837 , 0.95607967]),\n",
              " 0.9117485025829065)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 525
        }
      ]
    },
    {
      "metadata": {
        "id": "wJiMzxcDx-R3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "d133af10-0b22-4c5e-a7d7-4d2285b846f3"
      },
      "cell_type": "code",
      "source": [
        "logit.fit(X_train, y_train)"
      ],
      "execution_count": 526,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
              "          n_jobs=None, penalty='l2', random_state=17, solver='liblinear',\n",
              "          tol=0.0001, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 526
        }
      ]
    },
    {
      "metadata": {
        "id": "aU3Rf9GTzoKu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logit_test_pred = logit.predict_proba(X_test)[:, 1]\n",
        "write_to_submission_file(logit_test_pred, 'subm1.csv') # 0.91288"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QoQ37LjeUWyP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this part of the assignment, you have learned how to use sparse matrices, train logistic regression models, create new features and selected the best ones, learned why you need to scale features, and how to select hyperparameters. That's a lot!"
      ]
    },
    {
      "metadata": {
        "id": "drDMd9qgFkFP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "2279afa4-8b53-473e-f04b-be51bd321800"
      },
      "cell_type": "code",
      "source": [
        "full_time  =  full_df[times] \n",
        "full_time.head(3)"
      ],
      "execution_count": 528,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time1</th>\n",
              "      <th>time2</th>\n",
              "      <th>time3</th>\n",
              "      <th>time4</th>\n",
              "      <th>time5</th>\n",
              "      <th>time6</th>\n",
              "      <th>time7</th>\n",
              "      <th>time8</th>\n",
              "      <th>time9</th>\n",
              "      <th>time10</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>session_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21669</th>\n",
              "      <td>2013-01-12 08:05:57</td>\n",
              "      <td>2013-01-12 08:05:57</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54843</th>\n",
              "      <td>2013-01-12 08:37:23</td>\n",
              "      <td>2013-01-12 08:37:23</td>\n",
              "      <td>2013-01-12 09:07:07</td>\n",
              "      <td>2013-01-12 09:07:09</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77292</th>\n",
              "      <td>2013-01-12 08:50:13</td>\n",
              "      <td>2013-01-12 08:50:14</td>\n",
              "      <td>2013-01-12 08:50:15</td>\n",
              "      <td>2013-01-12 08:50:15</td>\n",
              "      <td>2013-01-12 08:50:16</td>\n",
              "      <td>2013-01-12 08:50:16</td>\n",
              "      <td>2013-01-12 08:50:16</td>\n",
              "      <td>2013-01-12 08:50:16</td>\n",
              "      <td>2013-01-12 08:50:17</td>\n",
              "      <td>2013-01-12 08:50:17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         time1               time2               time3  \\\n",
              "session_id                                                               \n",
              "21669      2013-01-12 08:05:57 2013-01-12 08:05:57                 NaT   \n",
              "54843      2013-01-12 08:37:23 2013-01-12 08:37:23 2013-01-12 09:07:07   \n",
              "77292      2013-01-12 08:50:13 2013-01-12 08:50:14 2013-01-12 08:50:15   \n",
              "\n",
              "                         time4               time5               time6  \\\n",
              "session_id                                                               \n",
              "21669                      NaT                 NaT                 NaT   \n",
              "54843      2013-01-12 09:07:09                 NaT                 NaT   \n",
              "77292      2013-01-12 08:50:15 2013-01-12 08:50:16 2013-01-12 08:50:16   \n",
              "\n",
              "                         time7               time8               time9  \\\n",
              "session_id                                                               \n",
              "21669                      NaT                 NaT                 NaT   \n",
              "54843                      NaT                 NaT                 NaT   \n",
              "77292      2013-01-12 08:50:16 2013-01-12 08:50:16 2013-01-12 08:50:17   \n",
              "\n",
              "                        time10  \n",
              "session_id                      \n",
              "21669                      NaT  \n",
              "54843                      NaT  \n",
              "77292      2013-01-12 08:50:17  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 528
        }
      ]
    },
    {
      "metadata": {
        "id": "R5YSXKK4GyDg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_total_time(row): \n",
        "    time_length = row.shape[0] - 1 \n",
        "    i = time_length \n",
        "    while pd.isnull( row [ i ]): \n",
        "        i -= 1 \n",
        "    return (row[i] - row[0]) / np.timedelta64(1,'s')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wMuDugWE0xOM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "43d831b7-be25-4507-f5fd-ed19b498fb01"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "total_time = []\n",
        "for row in full_time.values:\n",
        "    total_time.append(get_total_time(row))\n",
        "total_time = np.array(total_time).reshape(-1,1).astype(int)"
      ],
      "execution_count": 530,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.65 s, sys: 6.99 ms, total: 2.66 s\n",
            "Wall time: 2.66 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KNHXzvDbFxg5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def  get_time_diff (row): \n",
        "    time_length = row.shape[0] - 1 \n",
        "    time_diff = [0]*time_length \n",
        "    i = 0 \n",
        "    while (i < time_length)and pd.notnull(row[i+1]): \n",
        "        time_diff[i] = (row[i+1] - row[i]) /np.timedelta64(1,'s') \n",
        "        i += 1 \n",
        "    return  time_diff"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v_ea1qgFFxC8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a0eeb2be-2e1b-4c1f-bbb1-614408bd89f7"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "time_diff = []\n",
        "for row in full_time.values:\n",
        "    time_diff.append (get_time_diff (row))\n",
        "time_diff = np.log1p(np.array(time_diff).astype(float))"
      ],
      "execution_count": 532,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 21.3 s, sys: 175 ms, total: 21.5 s\n",
            "Wall time: 21.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oH1ta4IiF8sO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Appending The Newly Created Features\n",
        "time_names = ['time_diff'+str(j) for j in range(1,10)] \n",
        "for ind, column_name in enumerate(time_names): \n",
        "    full_new_feat[column_name] = time_diff[:,ind] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZsN-Lm4dIBJR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "7e15abd3-d2ef-414a-d697-a09a4855d118"
      },
      "cell_type": "code",
      "source": [
        "full_new_feat.head(2)"
      ],
      "execution_count": 534,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start_month</th>\n",
              "      <th>n_unique_sites</th>\n",
              "      <th>start_hour</th>\n",
              "      <th>morning</th>\n",
              "      <th>time_diff1</th>\n",
              "      <th>time_diff2</th>\n",
              "      <th>time_diff3</th>\n",
              "      <th>time_diff4</th>\n",
              "      <th>time_diff5</th>\n",
              "      <th>time_diff6</th>\n",
              "      <th>time_diff7</th>\n",
              "      <th>time_diff8</th>\n",
              "      <th>time_diff9</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>session_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21669</th>\n",
              "      <td>201301.0</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54843</th>\n",
              "      <td>201301.0</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.487174</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            start_month  n_unique_sites  start_hour  morning  time_diff1  \\\n",
              "session_id                                                                 \n",
              "21669          201301.0               2           8        1         0.0   \n",
              "54843          201301.0               2           8        1         0.0   \n",
              "\n",
              "            time_diff2  time_diff3  time_diff4  time_diff5  time_diff6  \\\n",
              "session_id                                                               \n",
              "21669         0.000000    0.000000         0.0         0.0         0.0   \n",
              "54843         7.487174    1.098612         0.0         0.0         0.0   \n",
              "\n",
              "            time_diff7  time_diff8  time_diff9  \n",
              "session_id                                      \n",
              "21669              0.0         0.0         0.0  \n",
              "54843              0.0         0.0         0.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 534
        }
      ]
    },
    {
      "metadata": {
        "id": "gN6B6nECIRbD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_total_time(row): \n",
        "    time_length = row.shape[0] - 1 \n",
        "    i = time_length \n",
        "    while pd.isnull( row [ i ]): \n",
        "        i -= 1 \n",
        "    return (row[i] - row[0]) / np.timedelta64(1,'s')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s2Wlle1FITw6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0f040c2e-aed3-4b44-9547-6ee3ae476805"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "total_time = []\n",
        "for row in full_time.values:\n",
        "    total_time.append(get_total_time(row))\n",
        "total_time = np.array(total_time).reshape(-1,1).astype(int)"
      ],
      "execution_count": 536,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.6 s, sys: 11 ms, total: 2.61 s\n",
            "Wall time: 2.62 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3ZyYcqbkIaCu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "full_new_feat['total_time'] =  total_time \n",
        "full_new_feat['total_time'] =  np.log1p(full_new_feat['total_time'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6v1ftXYj1dII",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Your code is here\n",
        "full_new_feat['day']  = full_new_feat['start_hour'].apply(lambda x: 1 if ((x >= 12) & (x <= 18)) else 0 )\n",
        "\n",
        "full_new_feat['evening']  = full_new_feat['start_hour'].apply(lambda x: 1 if ((x >= 19) & (x <= 23)) else 0 )\n",
        "\n",
        "full_new_feat['night']  = full_new_feat['start_hour'].apply(lambda x: 1 if ((x >= 0) & (x <= 6)) else 0 )\n",
        "\n",
        "full_new_feat['holiday']     = (full_df['time1'].dt.dayofweek >= 5).astype(int) \n",
        "\n",
        "full_new_feat['day_of_week'] = (full_df['time1'].dt.dayofweek).astype(int)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UZFaDqwZIlAv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "766c0728-d001-4dc4-8186-e21d7b803725"
      },
      "cell_type": "code",
      "source": [
        "full_new_feat.head(3)"
      ],
      "execution_count": 539,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start_month</th>\n",
              "      <th>n_unique_sites</th>\n",
              "      <th>start_hour</th>\n",
              "      <th>morning</th>\n",
              "      <th>time_diff1</th>\n",
              "      <th>time_diff2</th>\n",
              "      <th>time_diff3</th>\n",
              "      <th>time_diff4</th>\n",
              "      <th>time_diff5</th>\n",
              "      <th>time_diff6</th>\n",
              "      <th>time_diff7</th>\n",
              "      <th>time_diff8</th>\n",
              "      <th>time_diff9</th>\n",
              "      <th>total_time</th>\n",
              "      <th>day</th>\n",
              "      <th>evening</th>\n",
              "      <th>night</th>\n",
              "      <th>holiday</th>\n",
              "      <th>day_of_week</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>session_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21669</th>\n",
              "      <td>201301.0</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54843</th>\n",
              "      <td>201301.0</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.487174</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.488294</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77292</th>\n",
              "      <td>201301.0</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.609438</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            start_month  n_unique_sites  start_hour  morning  time_diff1  \\\n",
              "session_id                                                                 \n",
              "21669          201301.0               2           8        1    0.000000   \n",
              "54843          201301.0               2           8        1    0.000000   \n",
              "77292          201301.0               6           8        1    0.693147   \n",
              "\n",
              "            time_diff2  time_diff3  time_diff4  time_diff5  time_diff6  \\\n",
              "session_id                                                               \n",
              "21669         0.000000    0.000000    0.000000         0.0         0.0   \n",
              "54843         7.487174    1.098612    0.000000         0.0         0.0   \n",
              "77292         0.693147    0.000000    0.693147         0.0         0.0   \n",
              "\n",
              "            time_diff7  time_diff8  time_diff9  total_time  day  evening  \\\n",
              "session_id                                                                 \n",
              "21669              0.0    0.000000         0.0    0.000000    0        0   \n",
              "54843              0.0    0.000000         0.0    7.488294    0        0   \n",
              "77292              0.0    0.693147         0.0    1.609438    0        0   \n",
              "\n",
              "            night  holiday  day_of_week  \n",
              "session_id                               \n",
              "21669           0        1            5  \n",
              "54843           0        1            5  \n",
              "77292           0        1            5  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 539
        }
      ]
    },
    {
      "metadata": {
        "id": "Lsdga12l008B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "d6f54049-edde-4e97-b5b1-3a37334c0821"
      },
      "cell_type": "code",
      "source": [
        "# Prepare the training and test data\n",
        "tmp_scaled = StandardScaler().fit_transform(full_new_feat[['start_month', 'start_hour', \n",
        "                                                           'morning', 'day',  'total_time', \n",
        "                                                          'holiday',\t'day_of_week']])\n",
        "X_train = csr_matrix(hstack([full_sites_sparse[:idx_split,:], \n",
        "                             tmp_scaled[:idx_split,:]]))\n",
        "X_test = csr_matrix(hstack([full_sites_sparse[idx_split:,:], \n",
        "                            tmp_scaled[idx_split:,:]]))\n",
        "\n",
        "# Train the model on the whole training data set using optimal regularization parameter\n",
        "lr = LogisticRegression(C=C, random_state=17, solver='liblinear').fit(X_train, y_train)\n",
        "\n",
        "# Capture the quality with default parameters\n",
        "score_C_1 = get_auc_lr_valid(X_train, y_train)\n",
        "print(score_C_1)\n",
        "\n",
        "# with C = 0.09 -- 0.92718(LB)\n",
        "# Make a prediction for the test set\n",
        "y_test = lr.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Write it to the submission file\n",
        "write_to_submission_file(y_test, 'baseline_4.csv')\n",
        "# 0.9684064913844325"
      ],
      "execution_count": 540,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9743164850320518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nukOFwYd58Lg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## tune regularization parameter C."
      ]
    },
    {
      "metadata": {
        "id": "HlWGzh0955TI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "c_values = np.logspace(-2, 2, 10)\n",
        "\n",
        "logit_grid_searcher = GridSearchCV(estimator=logit, param_grid={'C': c_values},\n",
        "                                  scoring='roc_auc', n_jobs=1, cv=time_split, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R2_IMLZUAIHj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "95d46242-e3df-4151-e86d-ad6f368d0809"
      },
      "cell_type": "code",
      "source": [
        "print(c_values)"
      ],
      "execution_count": 423,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.00000000e-02 2.78255940e-02 7.74263683e-02 2.15443469e-01\n",
            " 5.99484250e-01 1.66810054e+00 4.64158883e+00 1.29154967e+01\n",
            " 3.59381366e+01 1.00000000e+02]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kO6HNtcB6TSE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2231
        },
        "outputId": "cd5cbda2-4a32-45dc-bba8-d11971dec4b1"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "logit_grid_searcher.fit(X_train, y_train)"
      ],
      "execution_count": 417,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-417-cc7c1e5e1e3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'logit_grid_searcher.fit(X_train, y_train)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1303\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1306\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    924\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ZNDjMuqi8FDP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logit_grid_searcher.best_score_, logit_grid_searcher.best_params_\n",
        "\n",
        "logit_test_pred3 = logit_grid_searcher.predict_proba(X_test_new)[:, 1]\n",
        "write_to_submission_file(logit_test_pred3, 'subm3.csv') # 0.94242"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tFr8C_yzUWyQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Part 2. Freeride"
      ]
    },
    {
      "metadata": {
        "id": "JiS4s2StUWyQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src='https://github.com/shravankoninti/mlcourse.ai-1/blob/master/img/snowboard.jpg?raw=1' width=70%>\n",
        "\n",
        "*Yorko in Sheregesh, the best place in Russia for snowboarding and skiing.*"
      ]
    },
    {
      "metadata": {
        "id": "zqY3eapFUWyR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this part, you'll need to beat the 2 more baselines mentioned in the beginning of this assignment. No more step-by-step instructions. But it'll be very helpful for you to study the Kernel \"[Correct time-aware cross-validation scheme](https://www.kaggle.com/kashnitsky/correct-time-aware-cross-validation-scheme)\".\n",
        "\n",
        "Here are a few tips for finding new features: think about what you can come up with using existing features, try multiplying or dividing two of them, justify or decline your hypotheses with plots, extract useful information from time series data (time1 ... time10), do not hesitate to convert an existing feature (for example, take a logarithm), etc. Checkout other [Kernels](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2/kernels). We encourage you to try new ideas and models - it's fun!\n",
        "\n",
        "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai, pinned thread __#a2_alice__*\n",
        "\n",
        "When you get into Kaggle and Xgboost, you'll feel like that, and it's OK :)\n",
        "\n",
        "<img src='https://github.com/shravankoninti/mlcourse.ai-1/blob/master/img/xgboost_meme.jpg?raw=1' width=50%>\n",
        "\n",
        "*More nerdy jokes in the thread [\"Nerd Laughing Loud\"](https://www.kaggle.com/general/76963)*\n",
        "\n",
        "# Relax? Not yet\n",
        "\n",
        "That's it for this part of assignment 2. More credits will be given to the top 10 performers in this competition (from among current participants), check [course roadmap](https://mlcourse.ai/roadmap). Do not spoil the assignment and the competition - don't share high-performing kernels (with LB ROC AUC >= 0.95)."
      ]
    }
  ]
}